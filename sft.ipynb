{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef88e51-570c-4472-810a-85df7228204c",
   "metadata": {},
   "source": [
    "ACCELERATE_LOG_LEVEL=info accelerate launch --config_file recipes/accelerate_configs/deepspeed_zero3.yaml scripts/run_sft.py recipes/constitutional-ai/sft/config_{grok,anthropic}.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "344acfa1-8d99-4463-b106-44e108c88366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, set_seed\n",
    "\n",
    "from alignment.configs import DataArguments, DPOConfig, H4ArgumentParser, ModelArguments, SFTConfig\n",
    "from alignment.data import apply_chat_template, get_datasets\n",
    "from alignment.decontaminate import decontaminate_humaneval\n",
    "from alignment.model_utils import (\n",
    "    get_checkpoint,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    "    get_tokenizer,\n",
    "    is_adapter_model,\n",
    ")\n",
    "\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f933082-d81b-47a5-81f8-f477f646ba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:2169] 2024-11-17 21:41:10,513 >> PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "sys.argv = [\"notebook\", 'configs/sft_config.yaml']\n",
    "\n",
    "parser = H4ArgumentParser((ModelArguments, DataArguments, SFTConfig))\n",
    "model_args, data_args, training_args = parser.parse()\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c98e40b8-b810-4bc5-8607-dfa76c7ad8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArguments(base_model_revision=None, model_name_or_path='mistralai/Mistral-7B-Instruct-v0.1', model_revision='main', model_code_revision=None, torch_dtype='bfloat16', tokenizer_name_or_path=None, trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False, bnb_4bit_quant_storage='uint8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e4004c-c232-4e1c-8f1b-c9b009402ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataArguments(chat_template=\"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\", dataset_mixer={'HuggingFaceH4/cai-conversation-harmless': 1.0, 'HuggingFaceH4/ultrachat_200k': 1.0}, text_column='text', dataset_splits=['train_sft', 'test_sft'], dataset_configs=None, preprocessing_num_workers=12, truncation_side=None, auto_insert_empty_system_msg=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb80c5f-5054-4005-96b7-d81bf2b16078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SFTConfig(output_dir='data/mistral-7b-sft-constitutional-ai', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, eval_strategy=<IntervalStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=4, eval_accumulation_steps=None, eval_delay=0, torch_empty_cache_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1, max_steps=-1, lr_scheduler_type=<SchedulerType.COSINE: 'cosine'>, lr_scheduler_kwargs={}, warmup_ratio=0.1, warmup_steps=0, log_level='info', log_level_replica='warning', log_on_each_node=True, logging_dir='data/mistral-7b-sft-constitutional-ai/runs/Nov17_20-51-14_notebook2', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=True, logging_steps=5, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=100, save_total_limit=1, save_safetensors=True, save_on_each_node=False, save_only_model=False, restore_callback_states_from_checkpoint=False, no_cuda=False, use_cpu=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=True, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=None, dataloader_num_workers=0, dataloader_prefetch_factor=None, past_index=-1, run_name='data/mistral-7b-sft-constitutional-ai', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fsdp=[], fsdp_min_num_params=0, fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, fsdp_transformer_layer_cls_to_wrap=None, accelerator_config=AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False), deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_TORCH: 'adamw_torch'>, optim_args=None, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, dataloader_persistent_workers=False, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=True, resume_from_checkpoint=None, hub_model_id='mistral-7b-sft-constitutional-ai', hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, hub_always_push=False, gradient_checkpointing=True, gradient_checkpointing_kwargs={'use_reentrant': False}, include_inputs_for_metrics=False, include_for_metrics=[], eval_do_concat_batches=True, fp16_backend='auto', evaluation_strategy=None, push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, dispatch_batches=None, split_batches=None, include_tokens_per_second=False, include_num_input_tokens_seen=False, neftune_noise_alpha=None, optim_target_modules=None, batch_eval_metrics=False, eval_on_start=False, use_liger_kernel=False, eval_use_gather_object=False, average_tokens_across_devices=False, dataset_text_field='text', packing=False, max_seq_length=2048, dataset_num_proc=None, dataset_batch_size=1000, model_init_kwargs=None, dataset_kwargs=None, eval_packing=None, num_of_sequences=1024, chars_per_token=3.6, use_liger=False, hub_model_revision='main')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc543c1e-deb4-43e7-b461-dc25154f427e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bf405ff-967f-45f7-aff5-3ff565d7ddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:06 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0 distributed training: True, 16-bits training: False\n",
      "2024-11-17 21:01:06 - INFO - __main__ - Model parameters ModelArguments(base_model_revision=None, model_name_or_path='mistralai/Mistral-7B-v0.1', model_revision='main', model_code_revision=None, torch_dtype='bfloat16', tokenizer_name_or_path=None, trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False, bnb_4bit_quant_storage='uint8')\n",
      "2024-11-17 21:01:06 - INFO - __main__ - Data parameters DataArguments(chat_template=\"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\", dataset_mixer={'HuggingFaceH4/cai-conversation-harmless': 1.0, 'HuggingFaceH4/ultrachat_200k': 1.0}, text_column='text', dataset_splits=['train_sft', 'test_sft'], dataset_configs=None, preprocessing_num_workers=12, truncation_side=None, auto_insert_empty_system_msg=True)\n",
      "2024-11-17 21:01:06 - INFO - __main__ - Training/evaluation parameters SFTConfig(\n",
      "_n_gpu=0,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "chars_per_token=<CHARS_PER_TOKEN>,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "dataset_batch_size=1000,\n",
      "dataset_kwargs=None,\n",
      "dataset_num_proc=None,\n",
      "dataset_text_field=text,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_packing=None,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.EPOCH,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=4,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs={'use_reentrant': False},\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=mistral-7b-sft-constitutional-ai,\n",
      "hub_model_revision=main,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=info,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=data/mistral-7b-sft-constitutional-ai/runs/Nov17_20-58-35_notebook2,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=5,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_seq_length=2048,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "model_init_kwargs=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_of_sequences=1024,\n",
      "num_train_epochs=1,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=data/mistral-7b-sft-constitutional-ai,\n",
      "overwrite_output_dir=True,\n",
      "packing=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=True,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=data/mistral-7b-sft-constitutional-ai,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# Setup logging\n",
    "###############\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process a small summary\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\" distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Model parameters {model_args}\")\n",
    "logger.info(f\"Data parameters {data_args}\")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de280731-9f8f-40a7-bd61-70693638b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for last checkpoint\n",
    "last_checkpoint = get_checkpoint(training_args)\n",
    "if last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "    logger.info(f\"Checkpoint detected, resuming training at {last_checkpoint=}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "587b10ea-425a-4035-9113-069b6e4dc69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "What is the historical significance of the pink stone extracted from Zacatecas quarry in Mexican architecture?</s>\n",
      "<|assistant|>\n",
      "The pink stone extracted from Zacatecas quarry in Mexican architecture is historically significant because it was widely used in the construction of colonial architecture in Mexico during the 16th century. This stone is a type of sandstone called cantera rosa, which has a pinkish color and is relatively easy to cut and carve. It was popular among Spanish architects and builders because of its beauty, durability, and availability in the region.\n",
      "\n",
      "Zacatecas became an important source of this pink stone during the colonial period, and it was used extensively in the construction of cathedrals, churches, government buildings, and private residences throughout Mexico. Some notable examples of cantera rosa architecture include the Cathedral of Our Lady of the Assumption in Mexico City, the Cathedral of Puebla, and the Templo de San Francisco in Zacatecas.\n",
      "\n",
      "Today, the use of cantera rosa is still an important part of Mexican architecture, and it is often used in restoration projects to maintain the authenticity of historic buildings.</s>\n",
      "<|user|>\n",
      "Can you tell me more about the process of extracting the pink stone and how it was transported to different parts of Mexico during the colonial period?</s>\n",
      "<|assistant|>\n",
      "The process of extracting the pink stone from the Zacatecas quarry involved several steps. First, the quarrymen would drill holes in the rock using hand-held tools and then fill the holes with water. As the water expanded, it would split the rock into blocks that could be easily removed.\n",
      "\n",
      "Once the blocks were extracted, they were shaped and cut into the desired size and shape using hand-held chisels and hammers. The finished stones were then transported to different parts of Mexico using various means of transportation depending on the distance and location. The most common modes of transportation during the colonial period were by mule, cart, or boat.\n",
      "\n",
      "The transportation process was often a difficult and time-consuming task as the roads were poorly developed and the terrain was often rough and uneven. However, the demand for cantera rosa was high and the material was regarded as a valuable commodity. Many of the buildings constructed using the pink stone were located in distant regions such as Oaxaca, Veracruz, and Chiapas.\n",
      "\n",
      "Despite the challenges, the transportation of cantera rosa played an essential role in the development of colonial architecture in Mexico, and the distinctive pink color and texture of this stone remain significant features of many historic buildings in the country.</s>\n",
      "<|user|>\n",
      "Can you tell me more about the specific tools that were used by the quarrymen to extract the pink stone?</s>\n",
      "<|assistant|>\n",
      "Sure, the tools used by the quarrymen to extract the pink stone from the Zacatecas quarry were traditional hand-held tools that were used for centuries in stone quarries around the world. These tools were made of high-quality steel and were designed to be used by skilled craftsmen who could shape and cut the stone with precision and accuracy.\n",
      "\n",
      "Some of the most common tools used by the quarrymen included:\n",
      "\n",
      "1. Chisels: Chisels were used to remove large pieces of stone from the quarry face. They came in different sizes and shapes, depending on the specific kind of stone that was being removed.\n",
      "\n",
      "2. Hammers: Quarry hammers were used to strike the chisels and break the stone into smaller pieces. These hammers were often sledgehammers or mallets and were designed to be heavy and durable.\n",
      "\n",
      "3. Wedges: Wedges were used to split large blocks of stone into smaller pieces. They were driven into pre-drilled holes and then tapped with a hammer until the stone broke apart.\n",
      "\n",
      "4. Saws: Saws were used to cut the stone into precise shapes and sizes. Wire saws were commonly used in the quarry, and the blades were cooled with water to prevent overheating.\n",
      "\n",
      "5. Drills: Drills were used to create holes in the stone for the insertion of wedges or for the placement of blasting charges.\n",
      "\n",
      "Overall, the quarrymen relied on their experience and skill to extract the pink stone from the quarry using these traditional hand-held tools.</s>\n",
      "<|user|>\n",
      "Could the quarrymen finish a block of cantera rosa in a day? How long did it usually take them to finish a project using this pink stone?</s>\n",
      "<|assistant|>\n",
      "The time it took quarrymen to finish a block of cantera rosa would depend on several factors, including the size, shape, and complexity of the block. Generally, it would take several days or even weeks to extract, cut, and shape a block of cantera rosa to the desired size and shape, depending on the level of intricacy required.\n",
      "\n",
      "For example, cutting a simple block for a wall might take a few days, while carving a decorative element for a façade might require several weeks or even months of work. Skilled craftsmen were often responsible for the more intricate carving and detailing, which required a high level of expertise and attention to detail.\n",
      "\n",
      "It is difficult to estimate how long it took to complete a project using cantera rosa, as it would depend on the scope and scale of the project. However, constructing a colonial-era cathedral or a large government building could take several years of dedicated labor from a team of skilled architects, builders, and craftsmen.\n",
      "\n",
      "In general, building with cantera rosa was a time-consuming and labor-intensive process, but the beauty and durability of the material made it worth the effort. The finished product was not only functional but also a piece of art that would last for generations.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets['train'][-1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da23fdae-b7ee-450f-b155-6cc5b081fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:53 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:53 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cai-conversation-harmless (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:53 - INFO - datasets.builder - Found cached dataset cai-conversation-harmless (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:53 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:54 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:54 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cai-conversation-harmless (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:55 - INFO - datasets.builder - Found cached dataset cai-conversation-harmless (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:55 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:56 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:56 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ultrachat_200k (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:56 - INFO - datasets.builder - Found cached dataset ultrachat_200k (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:56 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:58 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:58 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ultrachat_200k (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:58 - INFO - datasets.builder - Found cached dataset ultrachat_200k (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:58 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some of the datasets have disparate format. Resetting the format of the concatenated dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:58 - INFO - datasets.arrow_dataset - Some of the datasets have disparate format. Resetting the format of the concatenated dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-ed939b0339b874d1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:58 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-ed939b0339b874d1.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some of the datasets have disparate format. Resetting the format of the concatenated dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:58 - INFO - datasets.arrow_dataset - Some of the datasets have disparate format. Resetting the format of the concatenated dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-e4c1e667b15edf7c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:27:58 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-e4c1e667b15edf7c.arrow\n"
     ]
    }
   ],
   "source": [
    "test_data = get_datasets(\n",
    "    data_args,\n",
    "    splits=data_args.dataset_splits,\n",
    "    configs=data_args.dataset_configs,\n",
    "    columns_to_keep=[\"messages\", \"chosen\", \"rejected\", \"prompt\", \"completion\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca0b6a3e-f575-4713-bd35-d7d1ba05c8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db99d693520e43c8a4e20a468f0a1c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset cai-conversation-harmless (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:42 - INFO - datasets.builder - Generating dataset cai-conversation-harmless (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cai-conversation-harmless/default to /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:42 - INFO - datasets.builder - Downloading and preparing dataset cai-conversation-harmless/default to /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9634f2e1114805b14c657c7a2a90c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-7f69edecc397f342.parquet:   0%|          | 0.00/35.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1936b28e4580464980584d614316d830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-32cbb1e30771a5e7.parquet:   0%|          | 0.00/35.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e591b9a11dc4c2690cc29d23ef7425a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-96844167dbb0a822.parquet:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b6dffc1c4e4f129852e84b03954426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-f0c5cd137d4c1d93.parquet:   0%|          | 0.00/2.01M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:47 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:47 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train_sft split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:47 - INFO - datasets.builder - Generating train_sft split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e78a19bc624d3888ebde2515e6a7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_sft split:   0%|          | 0/21268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train_prefs split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:50 - INFO - datasets.builder - Generating train_prefs split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef3ec32796d455a9c06a078e03d65ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_prefs split:   0%|          | 0/21269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test_sft split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:54 - INFO - datasets.builder - Generating test_sft split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e009a48254c463bac5c2f41359e1244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_sft split:   0%|          | 0/1156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test_prefs split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:54 - INFO - datasets.builder - Generating test_prefs split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092ea349277f44ff909015bae680416e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_prefs split:   0%|          | 0/1156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the splits matched successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:54 - INFO - datasets.utils.info_utils - All the splits matched successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset cai-conversation-harmless downloaded and prepared to /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:54 - INFO - datasets.builder - Dataset cai-conversation-harmless downloaded and prepared to /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:56 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:56 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cai-conversation-harmless (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:56 - INFO - datasets.builder - Found cached dataset cai-conversation-harmless (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:01:56 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b353249ecea4fceb6b6b43c2b2c2aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset ultrachat_200k (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:02:00 - INFO - datasets.builder - Generating dataset ultrachat_200k (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ultrachat_200k/default to /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:02:00 - INFO - datasets.builder - Downloading and preparing dataset ultrachat_200k/default to /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1eff5352bd42e8bbc4367027b96006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00003-a3ecf92756993583.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3644166382a466d9cad4383c034ac87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00003-0a1804bcb6ae68c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d203d022ad84ebca96c17fbe0836b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00003-ee46ed25cfae92c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293672795f74437b8061baee041a514c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-f7dfac4afe5b93f4.parquet:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0da04fd8870411e9cfaf446e1f1aa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00003-a6c9fb894be3e50b.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa2fb38da46487f852457ad3db25ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00003-d6a0402e417f35ca.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cf9c8a00ef40578dcd97e1e31c5658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00003-c0db75b92a2f48fd.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9536dc0fccdb4a7a94d1d142d77bc37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-3d4cd8309148a71f.parquet:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:02:55 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:02:55 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train_sft split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:02:55 - INFO - datasets.builder - Generating train_sft split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986c50baf91a418784bfd31ed051a71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_sft split:   0%|          | 0/207865 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test_sft split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:03:47 - INFO - datasets.builder - Generating test_sft split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f4c99795be4d3fa2229afd85961e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_sft split:   0%|          | 0/23110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train_gen split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:03:52 - INFO - datasets.builder - Generating train_gen split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3b6473b2b242ec80c038694795ca1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_gen split:   0%|          | 0/256032 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test_gen split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:04:53 - INFO - datasets.builder - Generating test_gen split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c42c5df09e4443bb0fecba534088142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_gen split:   0%|          | 0/28304 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the splits matched successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:00 - INFO - datasets.utils.info_utils - All the splits matched successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset ultrachat_200k downloaded and prepared to /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:00 - INFO - datasets.builder - Dataset ultrachat_200k downloaded and prepared to /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:03 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:03 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ultrachat_200k (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:03 - INFO - datasets.builder - Found cached dataset ultrachat_200k (/arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:03 - INFO - datasets.info - Loading Dataset info from /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/8049631c405ae6576f93f445c6b8166f76f5505a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some of the datasets have disparate format. Resetting the format of the concatenated dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:03 - INFO - datasets.arrow_dataset - Some of the datasets have disparate format. Resetting the format of the concatenated dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching indices mapping at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-ed939b0339b874d1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:03 - INFO - datasets.arrow_dataset - Caching indices mapping at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-ed939b0339b874d1.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some of the datasets have disparate format. Resetting the format of the concatenated dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:03 - INFO - datasets.arrow_dataset - Some of the datasets have disparate format. Resetting the format of the concatenated dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching indices mapping at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-e4c1e667b15edf7c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:05:03 - INFO - datasets.arrow_dataset - Caching indices mapping at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-e4c1e667b15edf7c.arrow\n",
      "2024-11-17 21:05:03 - INFO - __main__ - Training on the following datasets and their proportions: ['train : 229133', 'test : 24266']\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# Load datasets\n",
    "###############\n",
    "raw_datasets = get_datasets(\n",
    "    data_args,\n",
    "    splits=data_args.dataset_splits,\n",
    "    configs=data_args.dataset_configs,\n",
    "    columns_to_keep=[\"messages\", \"chosen\", \"rejected\", \"prompt\", \"completion\", \"label\"],\n",
    ")\n",
    "logger.info(\n",
    "    f\"Training on the following datasets and their proportions: {[split + ' : ' + str(dset.num_rows) for split, dset in raw_datasets.items()]}\"\n",
    ")\n",
    "column_names = list(raw_datasets[\"train\"].features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b9a4e02-1928-44aa-8f18-13f6dbf25b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2211] 2024-11-17 21:07:48,538 >> loading file tokenizer.model from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-17 21:07:48,539 >> loading file tokenizer.json from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-17 21:07:48,540 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-17 21:07:48,540 >> loading file special_tokens_map.json from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-17 21:07:48,541 >> loading file tokenizer_config.json from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:07:48 - INFO - __main__ - *** Load pretrained model ***\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Load tokenizer\n",
    "################\n",
    "tokenizer = get_tokenizer(model_args, data_args)\n",
    "\n",
    "#######################\n",
    "# Load pretrained model\n",
    "#######################\n",
    "logger.info(\"*** Load pretrained model ***\")\n",
    "torch_dtype = (\n",
    "    model_args.torch_dtype if model_args.torch_dtype in [\"auto\", None] else getattr(torch, model_args.torch_dtype)\n",
    ")\n",
    "quantization_config = get_quantization_config(model_args)\n",
    "\n",
    "model_kwargs = dict(\n",
    "    revision=model_args.model_revision,\n",
    "    trust_remote_code=model_args.trust_remote_code,\n",
    "    attn_implementation=model_args.attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    use_cache=False if training_args.gradient_checkpointing else True,\n",
    "    device_map=get_kbit_device_map() if quantization_config is not None else None,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "model = model_args.model_name_or_path\n",
    "# For ChatML we need to add special tokens and resize the embedding layer\n",
    "if \"<|im_start|>\" in tokenizer.chat_template and \"gemma-tokenizer-chatml\" not in tokenizer.name_or_path:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_args.model_name_or_path, **model_kwargs)\n",
    "    model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "    model_kwargs = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340e0d9-c799-4482-a130-295a4e9558d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5697a74b-752a-48df-96f2-069f1cdaf4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #0 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00000_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #0 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00000_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #1 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00001_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #1 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00001_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #2 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00002_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #2 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00002_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #3 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00003_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #3 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00003_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #4 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00004_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #4 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00004_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #5 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00005_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #5 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00005_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #6 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00006_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #6 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00006_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #7 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00007_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #7 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00007_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #8 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00008_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #8 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00008_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #9 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00009_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #9 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00009_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #10 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00010_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #10 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00010_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #11 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00011_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:13 - INFO - datasets.arrow_dataset - Process #11 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00011_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spawning 12 processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:14 - INFO - datasets.arrow_dataset - Spawning 12 processes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e48f4a615f42ffbd28c5ba3f1c4acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template (num_proc=12):   0%|          | 0/229133 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00000_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00000_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00001_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00001_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00002_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00002_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00003_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00003_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00004_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00004_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00005_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00005_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00006_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00006_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00007_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00007_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00009_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00009_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00008_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00008_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00010_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00010_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00011_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-930193f3e0e437e9_00011_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating 12 shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Concatenating 12 shards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #0 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00000_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #0 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00000_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #1 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00001_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #1 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00001_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #2 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00002_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #2 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00002_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #3 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00003_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #3 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00003_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #4 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00004_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #4 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00004_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #5 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00005_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #5 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00005_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #6 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00006_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #6 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00006_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #7 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00007_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #7 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00007_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #8 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00008_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #8 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00008_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #9 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00009_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #9 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00009_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #10 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00010_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #10 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00010_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #11 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00011_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Process #11 will write at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00011_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spawning 12 processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:30 - INFO - datasets.arrow_dataset - Spawning 12 processes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890f13c6d1844baa9e29dbaf42c4512b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template (num_proc=12):   0%|          | 0/24266 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00001_of_00012.arrow\n",
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00000_of_00012.arrow\n",
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00002_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:31 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00001_of_00012.arrow\n",
      "2024-11-17 21:08:31 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00002_of_00012.arrow\n",
      "2024-11-17 21:08:31 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00000_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00003_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:31 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00003_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00004_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:31 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00004_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00005_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:31 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00005_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00006_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:31 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00006_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00007_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:31 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00007_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00008_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00008_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00009_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00009_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00010_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00010_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00011_of_00012.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-642247be3e8a328a_00011_of_00012.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating 12 shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:08:34 - INFO - datasets.arrow_dataset - Concatenating 12 shards\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Apply chat template\n",
    "#####################\n",
    "raw_datasets = raw_datasets.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"task\": \"sft\",\n",
    "        \"auto_insert_empty_system_msg\": data_args.auto_insert_empty_system_msg,\n",
    "    },\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60996a9a-e65f-44a7-80a8-0bd53e831c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "People who inject drugs support the use of new, safer ‘low dead space’ syringes, our research has found.\n",
      "A low dead space syringe has less space between the needle and the plunger when it’s fully pushed in, compared to traditional injecting equipment. It also has a detachable needle. The ‘dead’ space in a syringe holds blood after it’s been used. Previous research has found that low dead space syringes could reduce the chance of spreading infections, such as HIV and hepatitis C, if they’re re-used or shared.\n",
      "This diagram shows how syringe design can affect the amount of blood collected and transmitted when sharing needles. The far left shows a very high dead space syringe, and the far right is the lowest.\n",
      "Needle exchanges supply sterile equipment to people who inject drugs, to stop people having to share with others. But sometimes equipment still gets re-used or shared. If exchanges switch to this new type of syringe, it would help protect people from infection.\n",
      "But we didn’t know if people who inject drugs would be willing to use this new equipment.\n",
      "This project was a collaboration with the NIHR Health Protection Research Unit (HPRU) in Evaluation of Interventions.\n",
      "We aimed to find out whether people who inject drugs would be willing to switch to this new, safer equipment.\n",
      "We reviewed the existing research on these syringes and whether people minded using them. We also interviewed 23 people who inject drugs, and 13 volunteers and professionals who work with them, from Bristol and Bath. We aimed to explore their views on detachable low dead space syringes, and decide whether any additional support is needed to encourage their use.\n",
      "The Bristol Drugs Project (BDP) provides needle exchange services in Bristol. People who use BDP’s services were on the project steering group. Involving people who inject drugs was vital. They offered important insights into our findings and plans for implementation.\n",
      "It can be a challenge to engage with people who inject drugs because of their addictions and circumstances. BDP identified which of their service would be willing and able to participate in the steering group, and helped them attend meetings.\n",
      "From the BDP service user perspective, this project was an enjoyable and empowering experience. We learnt how valuable it is to enable their engagement, through practical support and by making an effort to explain the terms used during meetings.\n",
      "Decisions about injecting, including the choice of equipment, where to inject on the body and whether to rinse or re-use equipment, were influenced by a number of things. These included early experiences and being shown how to inject by others, and availability and awareness of alternative equipment. Avoiding or minimising problems such as difficulties finding a vein, vein damage and collapse, or pain due to abscesses and infections was also a factor.\n",
      "The relationship between rinsing and re-using syringes was complex: not rinsing risked re-use of unclean syringes if there was a shortage, while rinsing could encourage re-use.\n",
      "Most people who inject drugs found it difficult to change injecting equipment. If there weren’t any problems they saw no need to change and preferred using their usual equipment. However, if they did experience problems they tried to address them, and if there was a perceived benefit they may be willing to consider change.\n",
      "Needles and syringes were not only a tool for injecting the drug, but they also formed part of a familiar routine. We thought it was likely people would be frustrated by having to change from familiar equipment, but that most people would be willing to try the new syringes if they understood the benefits. We thought they’d continue using them if they worked as well as the original equipment.\n",
      "Alongside the introduction of the new syringes, encouraging appropriate rinsing methods among those known to re-use or share equipment may also be necessary.\n",
      "This research has helped Bristol Drugs Project to anticipate and respond to people’s worries about low dead space syringes. Some people using their service are now beginning to accept them.\n",
      "We have developed materials to support introducing these syringes, including a flyer for needle exchanges to inform people who inject drugs about the new equipment. We are also developing a step-by-step guide for needle exchanges.\n",
      "Our findings are relevant to the National Institute of Clinical Excellence and Care (NICE) who produce guidance for needle exchanges.\n",
      "This research is now being implemented through a project to develop materials promoting the use of low dead space equipment among people who inject drugs and needle and syringe programmes. How has this research helped inform the Bristol Drugs Project's approach to promoting the use of low dead space syringes, and what materials have they developed to support this effort?</s>\n",
      "<|assistant|>\n",
      "The research helped the Bristol Drugs Project anticipate and respond to people's concerns about low dead space syringes and develop materials to support their introduction. This included a flyer for informing people who inject drugs about the new equipment and a step-by-step guide for needle exchanges. The project also involved involving people who inject drugs in the steering group to offer important insights into the findings and plans for implementation. The project's findings are relevant to the National Institute of Clinical Excellence and Care (NICE), which produces guidance for needle exchanges. The research is now being implemented through a project to develop materials promoting the use of low dead space equipment among people who inject drugs and needle and syringe programs.</s>\n",
      "<|user|>\n",
      "Can you provide more details about the materials developed by the Bristol Drugs Project to support the introduction of low dead space syringes?</s>\n",
      "<|assistant|>\n",
      "The materials developed by the Bristol Drugs Project to support the introduction of low dead space syringes include:\n",
      "\n",
      "1. A flyer: This flyer is aimed at needle exchanges to inform people who inject drugs about the new equipment. It explains what low dead space syringes are, why they are safer, and how to use them.\n",
      "\n",
      "2. A step-by-step guide: The Bristol Drugs Project has developed a step-by-step guide for needle exchanges to help implement the use of low dead space syringes. This guide provides practical advice on how to introduce the new equipment, including training staff, promoting their use, and monitoring their effectiveness.\n",
      "\n",
      "3. Training materials: The Bristol Drugs Project has also developed training materials for staff at needle exchanges to help them understand the benefits of low dead space syringes and how to use them.\n",
      "\n",
      "Overall, these materials are designed to help promote the use of low dead space syringes and reduce the risk of infection among people who inject drugs. They provide practical information and guidance for needle exchanges, as well as for people who inject drugs themselves.</s>\n",
      "<|user|>\n",
      "Can you provide more information on how the low dead space syringes reduce the chance of spreading infections among people who inject drugs?</s>\n",
      "<|assistant|>\n",
      "Sure, traditional syringes used for injecting drugs have a small amount of space between the needle and the plunger when the plunger is fully pushed in. This space, known as the \"dead space,\" can hold blood or other fluids after the syringe is used. If a syringe with a high dead space is shared or reused, it can potentially transmit blood-borne infections such as HIV and hepatitis C, as small amounts of infected blood may remain in the dead space.\n",
      "\n",
      "Low dead space syringes, on the other hand, have less space between the needle and the plunger when it's fully pushed in. This means there is less space for blood to remain after the syringe is used. Studies have shown that low dead space syringes can significantly reduce the risk of transmission of blood-borne infections when compared to traditional syringes.\n",
      "\n",
      "Furthermore, the detachable needle of the low dead space syringe allows for safe disposal of the needle after use, reducing the risk of needle-stick injuries and the potential transmission of infections. \n",
      "\n",
      "Overall, the use of low dead space syringes is an important harm reduction measure that can help to protect individuals from blood-borne infections and improve the overall health outcomes of people who inject drugs.</s>\n",
      "<|user|>\n",
      "Can you provide any information on how effective the implementation of low dead space syringes has been so far in reducing the spread of blood-borne infections among people who inject drugs?</s>\n",
      "<|assistant|>\n",
      "While the implementation of low dead space syringes is still relatively new, studies have shown promising results in reducing the spread of blood-borne infections among people who inject drugs. \n",
      "\n",
      "For example, a study published in the International Journal of Drug Policy found that the use of low dead space syringes reduced the transmission of HIV by 70% among people who inject drugs in Scotland. Another study published in The Lancet HIV found that the use of low dead space syringes was associated with a reduced risk of hepatitis C virus acquisition among people who inject drugs. \n",
      "\n",
      "An evaluation of low dead space syringe distribution in Vancouver, Canada found that the risk of syringe sharing decreased by 42% after the implementation of low dead space syringes. Additionally, the percentage of syringes returned to needle exchanges that were contaminated with blood decreased from 44.5% to 1.3%, indicating a significant reduction in the risk of transmission of blood-borne infections.\n",
      "\n",
      "Overall, while more research is needed, the implementation of low dead space syringes has shown promise in reducing the spread of blood-borne infections among people who inject drugs. It is an important harm reduction measure that can help to protect the health of individuals who engage in this behavior.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets['train'][10]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b54f36e3-c376-478f-87fe-e8c20599ce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3d9d04217a4c8d92b069fef105da0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/229133 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-b4d769b59b776994.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:11:25 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-b4d769b59b776994.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e4d9fc4bdb44e082834504aeb08608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/24266 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-2a98584ccc9136fc.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:18:51 - INFO - datasets.arrow_dataset - Caching processed dataset at /arc/home/obriaint/huggingface/datasets/HuggingFaceH4___cai-conversation-harmless/default/0.0.0/51954823511ffd96d15ed6d1004949277e7af464/cache-2a98584ccc9136fc.arrow\n",
      "2024-11-17 21:19:16 - INFO - __main__ - Decontaminated 1 (0.00%) samples from the training set.\n",
      "2024-11-17 21:19:16 - INFO - __main__ - Sample 167621 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "Vinyl Premium Plastic Protector! The clear plastic protective case allows you to easily display your Pop vinyl character anywhere with style, while giving it a nice protective outer shell! Vinyl Figures in their original packaging can be protected the way collectibles are meant to be protected. The lid easily comes off to allow placement of the Pop! Vinyl Figure inside.\n",
      "Funko 3.75-Inch Vinyl Plastic POP Protector, Standard Packaging is rated 5.0 out of 5 by 3.\n",
      "Rated 5 out of 5 by Honeywest from Perfect Protector for A Loved Pop Bought to protect a Funko Pop Limited Edition. Very satisfied with everything product was designed to do.\n",
      "Rated 5 out of 5 by J from I would buy this product again. Works well protecting my collectibles.\n",
      "Rated 5 out of 5 by Valued from Great display case! I have a Pop figure, Asuna from Sword Art Online, who refuses to stand on her own. Her head is too heavy for her to stand well. My husband even tried gluing her to her stand but still nothing! I didn't keep her box because I didn't think that would be an issue but it was. So I got this case to put her in so she doesn't fall over. It's working well, she's just leaning against it.\n",
      "Can you provide more information on the Funko 3.75-Inch Vinyl Plastic POP Protector, Standard Packaging and its protective benefits for my vinyl figures?</s>\n",
      "<|assistant|>\n",
      "The Funko 3.75-Inch Vinyl Plastic POP Protector is a clear plastic case that provides a protective outer shell for your Pop vinyl figure. It is designed to allow you to easily display your Pop vinyl character while keeping it safe from dust, scratches, and damage. The protective case is ideal for keeping your collectibles in pristine condition, just as they are meant to be. Additionally, the lid of the protector easily comes off, allowing you to place your Pop vinyl figure inside with ease. This protective case is a must-have for any collector looking to keep their vinyl figures in top condition.</s>\n",
      "<|user|>\n",
      "Can you please help me find where I can purchase the Funko 3.75-Inch Vinyl Plastic POP Protector?</s>\n",
      "<|assistant|>\n",
      "You can purchase the Funko 3.75-Inch Vinyl Plastic POP Protector from several online retailers such as Amazon, Walmart, and Target. You can also find it on the official Funko website as well as other collectible retailers. It's always a good idea to check out multiple retailers to compare prices and shipping options before making your purchase.</s>\n",
      "<|user|>\n",
      "Could you please provide me with a link to an online retailer where I can purchase the Funko 3.75-Inch Vinyl Plastic POP Protector at a reasonable price?</s>\n",
      "<|assistant|>\n",
      "Sure, here is a link to the Funko 3.75-Inch Vinyl Plastic POP Protector on Amazon: https://www.amazon.com/Funko-3-75-Inch-Vinyl-Protector-Standard/dp/B00O2QFYKI. It is reasonably priced and has great customer reviews. Remember to always compare prices and shipping options from multiple retailers before making a purchase to ensure you get the best deal possible.</s>\n",
      "<|user|>\n",
      "Can you please help me find similar protective cases for other sizes of Funko Pop vinyl figures?</s>\n",
      "<|assistant|>\n",
      "Yes, certainly! Here are some protective cases for different sizes of Funko Pop vinyl figures:\n",
      "\n",
      "1. Funko Pop! 6-Inch Vinyl Protector - This case is designed to fit Funko Pop! figures that are 6 inches in height. You can find it on Amazon here: https://www.amazon.com/Funko-POP-6-Inch-Vinyl-Protector/dp/B00MY3CTV6\n",
      "\n",
      "2. Funko Pop! 2-Pack Vinyl Protector - This case is designed to fit Funko Pop! figures that come in a 2-pack. You can find it on Amazon here: https://www.amazon.com/Funko-Pop-Pack-Vinyl-Protector/dp/B07K7TMF83\n",
      "\n",
      "3. Funko Pop! Stacks Vinyl Protector - This case is designed to fit Funko Pop! figures that come in stacks, such as the Harry Potter or Marvel series. You can find it on Amazon here: https://www.amazon.com/Funko-Pop-Stacks-Vinyl-Protector/dp/B0036ZCN1G\n",
      "\n",
      "I hope this helps you find the right protective cases for your Funko Pop vinyl figures!</s>\n",
      "\n",
      "2024-11-17 21:19:16 - INFO - __main__ - Sample 29184 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "Please draft a contract that includes the scope of work, timeline, payment terms, confidentiality agreement, and termination clause for a freelance social media manager. The contract should clearly define the deliverables, communication expectations, and any additional fees or expenses. Please ensure that the contract reflects industry standards and legal requirements and is written in a professional, clear, and concise manner.</s>\n",
      "<|assistant|>\n",
      "CONTRACT FOR FREELANCE SOCIAL MEDIA MANAGEMENT SERVICES\n",
      "\n",
      "This Freelance Social Media Management Services Agreement (the “Agreement”), made and entered into as of the date of electronic signature, by and between [Client] (the “Client”), and [Freelance Social Media Manager] (the “Freelancer”).\n",
      "\n",
      "Scope of Work. The Freelancer will perform social media management services for the Client as described in the attached Exhibit \"A\" (the \"Services\"). The Services shall be carried out by the Freelancer in a professional and timely manner.\n",
      "\n",
      "Timeline. Work will begin upon receipt of the signed Agreement and will be completed by the date agreed upon by both the Freelancer and the Client.\n",
      "\n",
      "Payment Terms. The Client shall pay the Freelancer at the rate of [insert amount] per hour/project. The Freelancer shall prepare an invoice and submit it electronically for work performed. Payment shall be made within 30 days of receipt of invoice.\n",
      "\n",
      "Confidentiality Agreement. The Freelancer acknowledges and agrees that he/she shall not disclose, use, or disseminate any confidential or proprietary information of the Client, including but not limited to trade secrets, marketing strategies, financial information, or business plans, without the prior written consent of the Client.\n",
      "\n",
      "Deliverables. The Freelancer shall provide to the Client weekly performance reports and any additional deliverables specified in Exhibit \"A.\"\n",
      "\n",
      "Communication. The Freelancer and the Client shall communicate regularly regarding the status of the Services. All communication shall be in writing, via email or text message.\n",
      "\n",
      "Additional Fees and Expenses. The Freelancer shall not incur any additional fees or expenses beyond what is agreed to in Exhibit \"A\" without prior written approval from the Client.\n",
      "\n",
      "Termination. Either party may terminate this Agreement without cause upon written notice to the other party. The Freelancer shall be paid for all work performed up until the date of termination. Any work-in-progress materials shall be delivered to the Client by the Freelancer upon termination.\n",
      "\n",
      "Independent Contractor. The Freelancer is an independent contractor and is not an employee or agent of the Client. The Freelancer shall be solely responsible for the payment of all expenses required to carry out the Services.\n",
      "\n",
      "Governing Law. This Agreement shall be governed by and construed in accordance with the laws of the state of [insert state of jurisdiction].\n",
      "\n",
      "Entire Agreement. This Agreement constitutes the entire agreement between the parties and supersedes all prior agreements and understandings, whether written or oral.\n",
      "\n",
      "IN WITNESS WHEREOF, the Client and the Freelancer have executed this Agreement electronically as of the date first written above.\n",
      "\n",
      "[Client Signature, Date Signed]\n",
      "\n",
      "[Freelancer Signature, Date Signed]\n",
      "\n",
      "EXHIBIT \"A\"\n",
      "\n",
      "Scope of Work:\n",
      "\n",
      "1. Develop and implement social media campaigns across multiple platforms (Facebook, Twitter, LinkedIn, Instagram) to increase brand awareness and drive website traffic.\n",
      "\n",
      "2. Create and post content (including images, blogs, and videos) that aligns with the Client’s brand voice and target audience.\n",
      "\n",
      "3. Monitor and respond to comments and messages in a prompt and professional manner.\n",
      "\n",
      "4. Analyze social media metrics and adjust strategies as needed to improve engagement and reach.\n",
      "\n",
      "5. Provide a weekly report summarizing social media performance and future plans.\n",
      "\n",
      "Additional Deliverables:\n",
      "\n",
      "1. Two monthly blog posts.\n",
      "\n",
      "2. Monthly email newsletter.\n",
      "\n",
      "3. Two quarterly reports analyzing social media trends and their impact on the Client’s business.</s>\n",
      "<|user|>\n",
      "This looks great so far. Can you please add more information about the metrics that will be analyzed and how they will be reported? I want to make sure we have a clear understanding of the performance of the social media campaigns.</s>\n",
      "<|assistant|>\n",
      "Yes, absolutely. Here's an updated version that includes more information about the metrics and reporting:\n",
      "\n",
      "CONTRACT FOR FREELANCE SOCIAL MEDIA MANAGEMENT SERVICES\n",
      "\n",
      "This Freelance Social Media Management Services Agreement (the “Agreement”), made and entered into as of the date of electronic signature, by and between [Client] (the “Client”), and [Freelance Social Media Manager] (the “Freelancer”).\n",
      "\n",
      "Scope of Work. The Freelancer will perform social media management services for the Client as described in the attached Exhibit \"A\" (the \"Services\"). The Services shall be carried out by the Freelancer in a professional and timely manner.\n",
      "\n",
      "Timeline. Work will begin upon receipt of the signed Agreement and will be completed by the date agreed upon by both the Freelancer and the Client.\n",
      "\n",
      "Payment Terms. The Client shall pay the Freelancer at the rate of [insert amount] per hour/project. The Freelancer shall prepare an invoice and submit it electronically for work performed. Payment shall be made within 30 days of receipt of invoice.\n",
      "\n",
      "Confidentiality Agreement. The Freelancer acknowledges and agrees that he/she shall not disclose, use, or disseminate any confidential or proprietary information of the Client, including but not limited to trade secrets, marketing strategies, financial information, or business plans, without the prior written consent of the Client.\n",
      "\n",
      "Deliverables. The Freelancer shall provide to the Client weekly performance reports and any additional deliverables specified in Exhibit \"A.\"\n",
      "\n",
      "Communication. The Freelancer and the Client shall communicate regularly regarding the status of the Services. All communication shall be in writing, via email or text message.\n",
      "\n",
      "Additional Fees and Expenses. The Freelancer shall not incur any additional fees or expenses beyond what is agreed to in Exhibit \"A\" without prior written approval from the Client.\n",
      "\n",
      "Termination. Either party may terminate this Agreement without cause upon written notice to the other party. The Freelancer shall be paid for all work performed up until the date of termination. Any work-in-progress materials shall be delivered to the Client by the Freelancer upon termination.\n",
      "\n",
      "Independent Contractor. The Freelancer is an independent contractor and is not an employee or agent of the Client. The Freelancer shall be solely responsible for the payment of all expenses required to carry out the Services.\n",
      "\n",
      "Governing Law. This Agreement shall be governed by and construed in accordance with the laws of the state of [insert state of jurisdiction].\n",
      "\n",
      "Entire Agreement. This Agreement constitutes the entire agreement between the parties and supersedes all prior agreements and understandings, whether written or oral.\n",
      "\n",
      "IN WITNESS WHEREOF, the Client and the Freelancer have executed this Agreement electronically as of the date first written above.\n",
      "\n",
      "[Client Signature, Date Signed]\n",
      "\n",
      "[Freelancer Signature, Date Signed]\n",
      "\n",
      "EXHIBIT \"A\"\n",
      "\n",
      "Scope of Work:\n",
      "\n",
      "1. Develop and implement social media campaigns across multiple platforms (Facebook, Twitter, LinkedIn, Instagram) to increase brand awareness and drive website traffic.\n",
      "\n",
      "2. Create and post content (including images, blogs, and videos) that aligns with the Client’s brand voice and target audience.\n",
      "\n",
      "3. Monitor and respond to comments and messages in a prompt and professional manner.\n",
      "\n",
      "4. Analyze social media metrics including engagement rates, reach, website traffic, and conversions, and adjust strategies as needed to improve performance.\n",
      "\n",
      "5. Provide a weekly report summarizing social media performance, including key metrics, trends, and insights. The report shall include a detailed breakdown of the data for each platform and a comparison to the previous week’s data.\n",
      "\n",
      "Additional Deliverables:\n",
      "\n",
      "1. Two monthly blog posts.\n",
      "\n",
      "2. Monthly email newsletter.\n",
      "\n",
      "3. Two quarterly reports analyzing social media trends and their impact on the Client’s business. The reports shall include a detailed breakdown of the metrics for each platform, comparisons to industry benchmarks, and recommendations for future strategies.\n",
      "\n",
      "The Freelancer shall use industry-standard social media analytics tools, such as Sprout Social or Hootsuite, to analyze the metrics. The purpose of the analysis is to assess the effectiveness of the social media campaigns and adjust the strategies accordingly.\n",
      "\n",
      "If there are any questions or concerns, the Freelancer shall promptly notify the Client in writing.</s>\n",
      "<|user|>\n",
      "Thank you for adding more information about the metrics and reporting. Would it be possible to also include a section on how we will track and analyze the effectiveness of paid social media campaigns, if we decide to pursue that in the future?</s>\n",
      "<|assistant|>\n",
      "Yes, I can absolutely add a section on how we will track and analyze paid social media campaigns. Here is an updated version of the contract that includes this information:\n",
      "\n",
      "CONTRACT FOR FREELANCE SOCIAL MEDIA MANAGEMENT SERVICES\n",
      "\n",
      "This Freelance Social Media Management Services Agreement (the “Agreement”), made and entered into as of the date of electronic signature, by and between [Client] (the “Client”), and [Freelance Social Media Manager] (the “Freelancer”).\n",
      "\n",
      "Scope of Work. The Freelancer will perform social media management services for the Client as described in the attached Exhibit \"A\" (the \"Services\"). The Services shall be carried out by the Freelancer in a professional and timely manner.\n",
      "\n",
      "Timeline. Work will begin upon receipt of the signed Agreement and will be completed by the date agreed upon by both the Freelancer and the Client.\n",
      "\n",
      "Payment Terms. The Client shall pay the Freelancer at the rate of [insert amount] per hour/project. The Freelancer shall prepare an invoice and submit it electronically for work performed. Payment shall be made within 30 days of receipt of invoice.\n",
      "\n",
      "Confidentiality Agreement. The Freelancer acknowledges and agrees that he/she shall not disclose, use, or disseminate any confidential or proprietary information of the Client, including but not limited to trade secrets, marketing strategies, financial information, or business plans, without the prior written consent of the Client.\n",
      "\n",
      "Deliverables. The Freelancer shall provide to the Client weekly performance reports and any additional deliverables specified in Exhibit \"A.\"\n",
      "\n",
      "Communication. The Freelancer and the Client shall communicate regularly regarding the status of the Services. All communication shall be in writing, via email or text message.\n",
      "\n",
      "Additional Fees and Expenses. The Freelancer shall not incur any additional fees or expenses beyond what is agreed to in Exhibit \"A\" without prior written approval from the Client.\n",
      "\n",
      "Termination. Either party may terminate this Agreement without cause upon written notice to the other party. The Freelancer shall be paid for all work performed up until the date of termination. Any work-in-progress materials shall be delivered to the Client by the Freelancer upon termination.\n",
      "\n",
      "Independent Contractor. The Freelancer is an independent contractor and is not an employee or agent of the Client. The Freelancer shall be solely responsible for the payment of all expenses required to carry out the Services.\n",
      "\n",
      "Governing Law. This Agreement shall be governed by and construed in accordance with the laws of the state of [insert state of jurisdiction].\n",
      "\n",
      "Entire Agreement. This Agreement constitutes the entire agreement between the parties and supersedes all prior agreements and understandings, whether written or oral.\n",
      "\n",
      "IN WITNESS WHEREOF, the Client and the Freelancer have executed this Agreement electronically as of the date first written above.\n",
      "\n",
      "[Client Signature, Date Signed]\n",
      "\n",
      "[Freelancer Signature, Date Signed]\n",
      "\n",
      "EXHIBIT \"A\"\n",
      "\n",
      "Scope of Work:\n",
      "\n",
      "1. Develop and implement organic social media campaigns across multiple platforms (Facebook, Twitter, LinkedIn, Instagram) to increase brand awareness and drive website traffic.\n",
      "\n",
      "2. Create and post content (including images, blogs, and videos) that aligns with the Client’s brand voice and target audience.\n",
      "\n",
      "3. Monitor and respond to comments and messages in a prompt and professional manner.\n",
      "\n",
      "4. Analyze social media metrics including engagement rates, reach, website traffic, and conversions, and adjust strategies as needed to improve performance.\n",
      "\n",
      "5. Provide a weekly report summarizing social media performance, including key metrics, trends, and insights. The report shall include a detailed breakdown of the data for each platform and a comparison to the previous week’s data.\n",
      "\n",
      "6. If the Client decides to pursue paid social media campaigns in the future, the Freelancer shall develop and implement targeted campaigns across approved platforms based on the Client's goals and budget.\n",
      "\n",
      "7. The Freelancer shall track and analyze the effectiveness of the paid social media campaigns, including metrics such as click-through rates, cost per click, and conversion rates. The Freelancer shall adjust the strategies as needed to improve performance.\n",
      "\n",
      "8. The Freelancer shall provide the Client with regular reports on the performance of the paid social media campaigns, including a breakdown of the metrics for each platform and recommendations for future strategies.\n",
      "\n",
      "Additional Deliverables:\n",
      "\n",
      "1. Two monthly blog posts.\n",
      "\n",
      "2. Monthly email newsletter.\n",
      "\n",
      "3. Two quarterly reports analyzing social media trends and their impact on the Client’s business. The reports shall include a detailed breakdown of the metrics for each platform, comparisons to industry benchmarks, and recommendations for future strategies.\n",
      "\n",
      "The Freelancer shall use industry-standard social media analytics tools, such as Sprout Social or Hootsuite, to track and analyze the metrics for both organic and paid social media campaigns. If there are any questions or concerns, the Freelancer shall promptly notify the Client in writing.\n",
      "\n",
      "By signing this Agreement, the Client agrees to pay for any additional expenses incurred by the Freelancer in connection with the paid social media campaigns, including but not limited to advertising fees and third-party software subscriptions. All expenses must be pre-approved in writing by the Client.\n",
      "\n",
      "The Client understands that the success of paid social</s>\n",
      "\n",
      "2024-11-17 21:19:16 - INFO - __main__ - Sample 6556 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "Provide practical and useful advice for individuals with disabilities and their companions who are planning to go camping. Suggestions can include tips on accessible camping locations, recommended gear and equipment, safety precautions, communication strategies, and anything else that can help make the experience more comfortable and enjoyable for everyone involved. Try to provide a mix of general tips as well as specific recommendations for different types of disabilities or mobility limitations. Additionally, feel free to share personal experiences and anecdotes that illustrate the challenges or successes of camping with a disability.</s>\n",
      "<|assistant|>\n",
      "Camping can be an enjoyable and rewarding experience for individuals with disabilities, but it requires careful planning and preparation. Here are some practical tips for a successful camping trip:\n",
      "\n",
      "1. Choose an accessible camping location: When selecting a campground, look for one that has accessible sites with level ground, paved paths, and accessible restrooms/showers. Also, consider the terrain and accessibility of nearby activities and attractions.\n",
      "\n",
      "2. Rent or invest in specialized gear: There are many specialized camping gear and equipment available that can make the experience more comfortable and safe, such as accessible tents, sleeping pads, camping chairs, and mobility aids. Look for gear that’s designed to accommodate your specific needs.\n",
      "\n",
      "3. Prepare for emergencies: Bring a first-aid kit, medications, and emergency supplies, such as a flashlight and extra batteries. Make sure everyone in your group knows what to do in case of an emergency.\n",
      "\n",
      "4. Communication strategies: Develop a plan to communicate effectively with companions or fellow campers, especially if you have hearing or speech impairments. Consider using communication boards, writing pads, or handheld radios.\n",
      "\n",
      "5. Plan for extra time and assistance: Camping can be physically and mentally exhausting, so plan for breaks, rest periods, and extra time to complete tasks. If you need assistance, communicate your needs to your companions or campground staff in advance.\n",
      "\n",
      "6. Connect with the campground staff: Get in touch with the campground staff before your trip to discuss your specific needs and ask questions about accessibility and services. This can help ensure a smooth and successful camping experience.\n",
      "\n",
      "7. Share your experiences: Share your camping experiences with others, including challenges and successes. This can help raise awareness and encourage others to explore the outdoors.\n",
      "\n",
      "Remember, with careful planning, preparation, and communication, camping can be a fun and rewarding experience for individuals with disabilities and their companions.</s>\n",
      "<|user|>\n",
      "Can you provide more specific recommendations for camping gear and equipment that would be useful for individuals with mobility limitations or who use wheelchairs?</s>\n",
      "<|assistant|>\n",
      "Certainly! Here are some specific recommendations for camping gear and equipment that can make the experience more comfortable and accessible for individuals with mobility limitations or who use wheelchairs:\n",
      "\n",
      "1. Accessible tent: An accessible tent is designed specifically to be more spacious and easier to enter and exit, with a large door and tall ceiling. Look for tents with wide openings and ample space for a wheelchair or mobility device. 2. Camping chair: Look for camping chairs that are sturdy, comfortable, and designed to provide support for individuals with limited mobility. Look for chairs with adjustable heights and armrests or with built-in footrests. 3. Portable ramp: A portable ramp can make it easier to access the tent, picnic area, or restroom. Look for lightweight and durable ramps that can support the weight of a wheelchair or mobility scooter. 4. Mobility scooter or electric wheelchair: If you use a mobility scooter or electric wheelchair, consider bringing it with you on your camping trip. Several companies manufacture scooters that are designed for rugged terrain, and they can improve your mobility and independence during your camping trip. 5. Waterproof gear: No matter the weather, waterproof gear such as jackets, rain pants, and backpack covers are essential for a comfortable camping experience. Make sure they fit well and provide enough room to comfortably move with them. 6. Portable shower: To make showering more accessible, consider bringing a portable shower with you. Portable showers (also called camping showers) are equipped with a water tank and a hose, allowing you to take a warm shower anywhere. 7. Mobility aids: If you need walking aids such as crutches, canes, or walkers, bring them with you. Additionally, off-road wheelchairs called \"all-terrain wheelchairs\" are designed to provide support on rugged trails. These are just a few examples of camping gear and equipment that can enhance the camping experience for individuals with mobility limitations or who use wheelchairs. Remember to choose gear that meets your specific needs and preferences to ensure a comfortable and enjoyable camping trip.</s>\n",
      "<|user|>\n",
      "Could you also suggest some camping locations that are particularly accessible for individuals with mobility limitations? Additionally, are there any resources or organizations that specialize in supporting accessible camping trips?</s>\n",
      "<|assistant|>\n",
      "Yes, here are some camping locations that are well-known for being accessible for individuals with mobility limitations:\n",
      "\n",
      "1. Yosemite National Park - Yosemite offers several ADA-compliant campsites, trails, and facilities. One of the trails in the park, the Lower Yosemite Fall Trail, is wheelchair accessible, and there are also wheelchair-accessible shuttle buses available. 2. Acadia National Park - Acadia offers several paved trails and campsites that are ADA-compliant. Additionally, the park offers a wheelchair-accessible bus tour that provides an overview of the park's history and natural features. 3. Lake Tahoe - Accessible campsites and lodging are available around the lake. The Tahoe Rim Trail, a 165-mile trail around the lake, offers wheelchair-accessible segments. 4. Grand Teton National Park - Grand Teton has several accessible trails, campsites, and facilities, including the Craig Thomas Discovery and Visitor Center, which is fully accessible. 5. Joshua Tree National Park - Joshua Tree has a number of ADA-compliant campsites, and several of the park's trails and rock formations are accessible, including the Jumbo Rocks accessible picnic area and restroom, which includes a paved path. In addition to accessible camping locations, there are several organizations that specialize in supporting accessible camping trips. Here are a few to consider:\n",
      "\n",
      "1. Wilderness On Wheels - Wilderness on Wheels is an organization that provides an accessible camping and outdoor recreational facility in Colorado that includes a 0.25-mile-long boardwalk and accessible restrooms and picnic areas. 2. National Ability Center - The National Ability Center provides a variety of outdoor programs, including adaptive camping and hiking trips, for individuals with disabilities. 3. Hands On Outdoor - Hands On Outdoor provides a variety of accessible outdoor adventures, including camping trips, for individuals with disabilities throughout California. 4. American Hiking Society - The American Hiking Society works to create accessible trails and hiking opportunities for individuals with disabilities and offers a database of accessible trails. These organizations and resources can help individuals with mobility limitations plan and enjoy an accessible camping trip.</s>\n",
      "<|user|>\n",
      "Thank you for providing all of this helpful information about accessible camping. Could you please provide some tips or resources for individuals with visual impairments who are interested in camping? How can they prepare and what gear might be useful for them?</s>\n",
      "<|assistant|>\n",
      "Certainly! Here are some tips and gear recommendations for individuals with visual impairments who are interested in camping:\n",
      "\n",
      "1. Plan ahead: If you have a visual impairment, proper planning is essential. Research your camping location beforehand, and familiarize yourself with the layout of the campground, trails, and facilities. Consider contacting the campground in advance to request information about their accessibility and accommodations.\n",
      "\n",
      "2. Use audio resources: Audio resources such as audio books, audio guides or audio descriptions can provide helpful explanations of the natural surroundings and provide an engaging experience. Some parks may even offer audio tours.\n",
      "\n",
      "3. Bring a sighted companion: Consider bringing a sighted companion with you to assist with navigation, reading maps and setting up the campsite.\n",
      "\n",
      "4. Tactile maps: An alternative is to use tactile maps, which can be useful for individuals with visual impairment. You can contact Parks & Recreation departments and request custom made tactile maps of your campsite and surrounding areas.\n",
      "\n",
      "5. Illuminated or tactile equipment: Consider using flashlights or headlamps with braille labels that can help illuminate the area during the night. Also, investing in an illuminated compass and an audio weather alert system can help keep you safe and aware of the weather conditions while camping.\n",
      "\n",
      "6. Guide dogs: Guide dogs can be helpful in navigating rough terrain or unfamiliar surroundings. Make sure your guide dog is properly trained and comfortable in outdoor settings.\n",
      "\n",
      "7. Choose equipment with high-visibility features: Consider gear with high-visibility features such as reflective strips, bright colors or contrasting patterns, that can be easily identified.\n",
      "\n",
      "8. Tents with clear windows: Tents with clear windows allow individuals with visual impairment to see outside even without the need for opening the tent door.\n",
      "\n",
      "These are just a few examples of tips and gear recommendations for individuals with visual impairments who are interested in camping. Remember to choose gear that meets your specific needs and preferences to ensure a comfortable and enjoyable camping trip. Additionally, consider reaching out to organizations such as the American Council of the Blind (ACB) and the National Federation of the Blind (NFB), as they provide resources and guidance on accessible camping for individuals with visual impairments.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# Decontaminate benchmarks\n",
    "##########################\n",
    "num_raw_train_samples = len(raw_datasets[\"train\"])\n",
    "raw_datasets = raw_datasets.filter(decontaminate_humaneval, batched=True, batch_size=10_000, num_proc=1)\n",
    "num_filtered_train_samples = num_raw_train_samples - len(raw_datasets[\"train\"])\n",
    "logger.info(\n",
    "    f\"Decontaminated {num_filtered_train_samples} ({num_filtered_train_samples/num_raw_train_samples * 100:.2f}%) samples from the training set.\"\n",
    ")\n",
    "\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "eval_dataset = raw_datasets[\"test\"]\n",
    "\n",
    "with training_args.main_process_first(desc=\"Log a few random samples from the processed training set\"):\n",
    "    for index in random.sample(range(len(raw_datasets[\"train\"])), 3):\n",
    "        logger.info(f\"Sample {index} of the processed training set:\\n\\n{raw_datasets['train'][index]['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4539608-1149-4504-abc6-a4c51c41378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs['attn_implementation'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca4cd866-92eb-40b1-9312-407f08f9fca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:679] 2024-11-17 21:42:06,479 >> loading configuration file config.json from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-17 21:42:06,484 >> Model config MistralConfig {\n",
      "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3937] 2024-11-17 21:42:06,487 >> loading weights file model.safetensors from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1670] 2024-11-17 21:42:06,489 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1096] 2024-11-17 21:42:06,491 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050324c3b6d14e41a64d9106cb87f5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4800] 2024-11-17 21:42:07,558 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4808] 2024-11-17 21:42:07,560 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1051] 2024-11-17 21:42:07,672 >> loading configuration file generation_config.json from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/generation_config.json\n",
      "[INFO|configuration_utils.py:1096] 2024-11-17 21:42:07,673 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:212: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Using custom data configuration default-da0fc66cc2bc9a67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:42:07 - INFO - datasets.builder - Using custom data configuration default-da0fc66cc2bc9a67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from /arc/home/obriaint/.local/lib/python3.11/site-packages/datasets/packaged_modules/generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:42:07 - INFO - datasets.info - Loading Dataset Infos from /arc/home/obriaint/.local/lib/python3.11/site-packages/datasets/packaged_modules/generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset generator (/arc/home/obriaint/huggingface/datasets/generator/default-da0fc66cc2bc9a67/0.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:42:07 - INFO - datasets.builder - Generating dataset generator (/arc/home/obriaint/huggingface/datasets/generator/default-da0fc66cc2bc9a67/0.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /arc/home/obriaint/huggingface/datasets/generator/default-da0fc66cc2bc9a67/0.0.0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:42:07 - INFO - datasets.builder - Downloading and preparing dataset generator/default to /arc/home/obriaint/huggingface/datasets/generator/default-da0fc66cc2bc9a67/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:42:07 - INFO - datasets.builder - Generating train split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5978ea4b584a978a281c14ab0b2c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|tokenization_utils_base.py:4089] 2024-11-17 21:42:12,892 >> Token indices sequence length is longer than the specified maximum sequence length for this model (2413 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:58:38 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /arc/home/obriaint/huggingface/datasets/generator/default-da0fc66cc2bc9a67/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:58:38 - INFO - datasets.builder - Dataset generator downloaded and prepared to /arc/home/obriaint/huggingface/datasets/generator/default-da0fc66cc2bc9a67/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4e38acd28db1e147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:58:38 - INFO - datasets.builder - Using custom data configuration default-4e38acd28db1e147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from /arc/home/obriaint/.local/lib/python3.11/site-packages/datasets/packaged_modules/generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:58:38 - INFO - datasets.info - Loading Dataset Infos from /arc/home/obriaint/.local/lib/python3.11/site-packages/datasets/packaged_modules/generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset generator (/arc/home/obriaint/huggingface/datasets/generator/default-4e38acd28db1e147/0.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:58:38 - INFO - datasets.builder - Generating dataset generator (/arc/home/obriaint/huggingface/datasets/generator/default-4e38acd28db1e147/0.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /arc/home/obriaint/huggingface/datasets/generator/default-4e38acd28db1e147/0.0.0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:58:38 - INFO - datasets.builder - Downloading and preparing dataset generator/default to /arc/home/obriaint/huggingface/datasets/generator/default-4e38acd28db1e147/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:58:38 - INFO - datasets.builder - Generating train split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475a6cad6d2a4de6a8a4e32fa5a18064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:00:26 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /arc/home/obriaint/huggingface/datasets/generator/default-4e38acd28db1e147/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 22:00:26 - INFO - datasets.builder - Dataset generator downloaded and prepared to /arc/home/obriaint/huggingface/datasets/generator/default-4e38acd28db1e147/0.0.0. Subsequent calls will reuse this data.\n",
      "2024-11-17 22:00:26 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:699] 2024-11-17 22:00:27,514 >> Using cpu_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# Initialize the Trainer\n",
    "########################\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    model_init_kwargs=model_kwargs,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=training_args.max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    peft_config=get_peft_config(model_args),\n",
    "    dataset_kwargs=training_args.dataset_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a5cb896-95fb-4e33-aff5-4eabb801dfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.dataset_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76030fec-0150-40e3-9884-bbfa8c6fa4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"<|system|>\\n</s>\\n<|user|>\\nSome commenters suggest that Ashley should make amends by contributing to a cancer society or center. Do you think this would be a fitting form of restitution? Why or why not?: Last year, Toronto’s press was all over the bizarre story of Ashley Anne Kirilow, the young woman from Burlington who shaved her head and eyebrows to fake the appearance of someone undergoing intense chemotherapy, and who managed to bilk around $12,000 from well-wishers. That story came to a close yesterday as Kirilow pleaded guilty to the last counts against her in court. The conditions of her sentence are, appropriately enough, as “interesting” as the crime itself.\\nKirilow, 23, who is now living in the psychiatric ward of Joseph Brant Memorial Hospital in Burlington, pleaded guilty Thursday to outstanding fraud charges and was given a 15-month conditional sentence without jail time. She had previously pleaded guilty to one charge of fraud over $5,000….\\nJointly submitted by the Crown and defence, and accepted by Justice Fred Forsythe, the sentence calls for 10 months of house arrest and five months under strict curfew, plus two years probation and 100 hours of community service. Kirilow is also barred from soliciting donations or canvassing for any charitable organization.\\nIt’s actually quite common. There are people walking around downtown every day, asking people to help them with bus fare to Hamilton, or their car broke down, or their girlfriend has locked them out…it’s more common than you think. Also for hot water heater repairs (read the news) and all kinds of door-to-door scams.\\nThis woman makes me sick. Karma will not be kind to her.\\npoor girl got caught….now she is history how about we pursue our politicians for their fraudulent crimes..\\nI think this is the most ridiculous thing I’ve ever heard in my life. My Grandmother, Aunt, and Cousin have all died because of cancer. Another of my cousin’s is currently raising her 2 nephews and niece because her brother had been killed in a motorcycle accident about 10 years ago, and his wife finally succumbed to cancer earlier this year after a long and painful battle. I’ve seen the suffering and pain chemotherapy causes. How could anyone want to fake that? This girl obviously has some serious mental issues to have come up with this scheme. And where are her parents and family through all of this? Wouldn’t they have thought it a little strange when their daughter showed up with a shaved head & eyebrows, and no eye lashes, when she’s perfectly healthy? I can’t believe that she’s not going to be doing some serious time behind bars. 10 months under house arrest and 5 months with a strict curfew as a punishment seems just laughable. The whole thing makes me sick.\\nWhy do people donate to cancer victims anyway? Be outraged at the idiots who fork over money at every opportunity then cry when they get scammed. I saw a kid at the beach selling painted rocks yesterday,I didn’t buy one. Wanna know why? Because I have no use for a painted rock.\\n…and she obviously has mental issues, shes in a psych ward. There’s too many “victims” out there, use your head people.\\nSurely, if restitution of the funds fraudulently obtained isn’t practical, then she should make a contribution to the Cancer Society or a cancer center at the very least equal to that amount. Whatever her problems, she knew what she was doing was wrong and she should pay for it.\\nThis poor excuse for a human being should have got the maximum sentence & her community service should be cleaning up the puke of chemo patients & emptying the bedpans of the REAL cancer victims for a very, very long time.\\nThis could very well come back & bite you in the A$$, Ashley & the little girl who cried wolf will have no believers because no one will give a crap!\\n@Tom: You have no idea what you’re talking about. She was a well-known friend to many people in the area who all thought she needed desperate help so they organized fund raisers for her. It would be the same no matter what disease it was.\\nClearly she has mental issues… and NOW she’s in a psych ward because she needs help. You’re getting it bass ackwards.</s>\\n<|assistant|>\\nSome commenters suggest that making a contribution to a cancer society or center would be a fitting form of restitution for Ashley Kirilow's crime. However, whether or not this is a fitting form of restitution is subjective. While it may be a way for Kirilow to make amends for her actions, it does not necessarily make up for the harm that she caused to those who donated to her false cause. Additionally, there may be better ways for Kirilow to contribute to society and make amends, such as volunteering for charitable organizations or helping those affected by cancer in a more direct way. Ultimately, the decision of how she should make amends should lie with the court and her rehabilitation professionals.</s>\\n<|user|>\\nCan you please provide me with more information about Ashley Kirilow's sentence and what the conditions of her sentence entail?</s>\\n<|assistant|>\\nAshley Kirilow was sentenced to a 15-month conditional sentence without jail time. She pleaded guilty to outstanding fraud charges and had previously pleaded guilty to one charge of fraud over $5,000. The conditions of her sentence include 10 months of house arrest and five months under strict curfew, plus two years probation and 100 hours of community service. Kirilow is also barred from soliciting donations or canvassing for any charitable organization. She is currently living in the psychiatric ward of Joseph Brant Memorial Hospital in Burlington.</s>\\n<|user|>\\nCan you tell me if there were any other proposed forms of restitution for Ashley Kirilow besides contributing to a cancer society or center?</s>\\n<|assistant|>\\nThere is no specific information available about any other proposed forms of restitution for Ashley Kirilow besides contributing to a cancer society or center. However, the court and her rehabilitation professionals may have considered other forms of restitution or community service for her as part of her sentence. The details of those potential options are not publicly available.</s>\\n<|user|>\\nCan you tell me if there were any specific organizations or cancer centers mentioned that Ashley Kirilow could potentially contribute to as part of her sentence?</s>\\n<|assistant|>\\nThere is no specific information available about any organizations or cancer centers that were mentioned that Ashley Kirilow could potentially contribute to as part of her sentence. If a contribution to a cancer society or center was considered as part of her sentence, it is likely that the court and her rehabilitation professionals would determine a suitable organization or center for her to contribute to. The details of any potential organizations or centers are not publicly available.</s>\\n\"}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7eb11fc-928b-475c-a9b1-0e89a18559eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainer.train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d32ad66c-7de1-484b-aa3f-5ec35f46476c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainer.train_dataset[1]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68970f85-868c-4f96-8d8a-1a19b2160322",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Training loop\n",
    "###############\n",
    "logger.info(\"*** Train ***\")\n",
    "checkpoint = None\n",
    "if training_args.resume_from_checkpoint is not None:\n",
    "    checkpoint = training_args.resume_from_checkpoint\n",
    "elif last_checkpoint is not None:\n",
    "    checkpoint = last_checkpoint\n",
    "train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "metrics = train_result.metrics\n",
    "metrics[\"train_samples\"] = len(train_dataset)\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3a032-c795-4db8-86b4-0b0c971d77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Save model and create model card\n",
    "##################################\n",
    "logger.info(\"*** Save model ***\")\n",
    "trainer.save_model(training_args.output_dir)\n",
    "logger.info(f\"Model saved to {training_args.output_dir}\")\n",
    "\n",
    "# Save everything else on main process\n",
    "kwargs = {\n",
    "    \"finetuned_from\": model_args.model_name_or_path,\n",
    "    \"dataset\": list(data_args.dataset_mixer.keys()),\n",
    "    \"dataset_tags\": list(data_args.dataset_mixer.keys()),\n",
    "    \"tags\": [\"alignment-handbook\"],\n",
    "}\n",
    "if trainer.accelerator.is_main_process:\n",
    "    trainer.create_model_card(**kwargs)\n",
    "    # Restore k,v cache for fast inference\n",
    "    trainer.model.config.use_cache = True\n",
    "    trainer.model.config.save_pretrained(training_args.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401d171-b38d-4a62-addf-c946a9269f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########\n",
    "# Evaluate\n",
    "##########\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate()\n",
    "    metrics[\"eval_samples\"] = len(eval_dataset)\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "if training_args.push_to_hub is True:\n",
    "    logger.info(\"Pushing to hub...\")\n",
    "    trainer.push_to_hub(**kwargs)\n",
    "\n",
    "logger.info(\"*** Training complete ***\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
