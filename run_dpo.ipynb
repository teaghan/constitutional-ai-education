{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64151b7d-1828-4384-b02c-fc7df300273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, set_seed\n",
    "\n",
    "from alignment.configs import DataArguments, DPOConfig, H4ArgumentParser, ModelArguments\n",
    "from alignment.data import apply_chat_template, get_datasets\n",
    "from alignment.decontaminate import decontaminate_humaneval\n",
    "from alignment.model_utils import (\n",
    "    get_checkpoint,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    "    get_tokenizer,\n",
    "    is_adapter_model,\n",
    ")\n",
    "\n",
    "from peft import PeftConfig, PeftModel\n",
    "from trl import DPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e588fda5-8e3f-4109-a263-3f3b1adcdfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from alignment.configs import DataArguments, DPOConfig, H4ArgumentParser, ModelArguments\n",
    "import sys\n",
    "\n",
    "sys.argv = [\"notebook\", 'recipes/constitutional-ai/dpo/config_anthropic.yaml']\n",
    "\n",
    "parser = H4ArgumentParser((ModelArguments, DataArguments, DPOConfig))\n",
    "model_args, data_args, training_args = parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38cd46e0-af3d-4b4e-9803-20ceb3ded59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_args.model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32b46375-039b-4f1f-b8ed-ca49a36e6ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_adapter_model(model, model_args.model_revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08eb0df8-6d45-4d2d-8f2b-4c8b897472c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'FDivergenceType'>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import FDivergenceType\n",
    "FDivergenceType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f237f9-3d07-46c0-a5c4-a9f6502b69b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from trl import DPOTrainer\n",
    "from utils.model import get_checkpoint, get_tokenizer\n",
    "from utils.data import load_dataset_from_csv, apply_chat_template, load_token\n",
    "from utils.config import DPOConfig, H4ArgumentParser\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "sys.argv = [\"notebook\", 'configs/dpo_config.yaml']#config_anthropic.yaml']\n",
    "\n",
    "parser = H4ArgumentParser((DPOConfig))\n",
    "training_args = parser.parse()\n",
    "\n",
    "pretrained_model_path = 'mistralai/Mistral-7B-Instruct-v0.1'\n",
    "output_model_path = 'models/mistral-7b-dpo-constitutional-ai'\n",
    "csv_files = ['data/train_dataset.csv', 'data/test_dataset.csv']\n",
    "split_labels = ['train', 'test']\n",
    "preprocessing_num_workers = 12\n",
    "beta = 0.1\n",
    "\n",
    "hf_token = load_token(file_path='hf_token.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc727185-1352-4b62-acc3-dbe79784adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = get_checkpoint(output_model_path)\n",
    "if last_checkpoint is not None:\n",
    "    print(f\"Checkpoint detected, resuming training at {last_checkpoint=}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d363654-a368-43db-b06c-093b8f5cf395",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(pretrained_model_path, token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83c1496-1178-475b-87ad-b243691e5919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on the following splits: ['train : 324', 'test : 42']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6331bb8ea694efb9c7ce6fe96c9b3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting comparisons with prompt template (num_proc=12):   0%|          | 0/324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00de0b25f684339acc5d0cee0ae86a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting comparisons with prompt template (num_proc=12):   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt sample 123 of the raw training set:\n",
      "\n",
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "Create a detailed infographic about the water cycle for my science project.</s>\n",
      "\n",
      "Rejected sample 123 of the raw training set:\n",
      "\n",
      "<|assistant|>\n",
      "Sure, here's a revised response:\n",
      "\n",
      "The next number in the sequence 2, 4,8,16,... would be determined by multiplying each successive term by two. This creates a sequence where each term is the previous term multiplied by two. In the case of this sequence, you can identify the pattern by observing that each term is obtained by multiplying the previous term by two (2×2=4, 4×2=8, 8×2=16, etc.). So, the next term in the sequence would be 16×2=32. This is the next number in the sequence if each term is obtained by multiplying the previous term by two.</s>\n",
      "\n",
      "Chosen sample 123 of the raw training set:\n",
      "\n",
      "<|assistant|>\n",
      "Sure, creating an infographic about the water cycle for your science project would be a great way to visualize and explain this natural process. Here's what I suggest:\n",
      "\n",
      "1. Introduction: Start by introducing the water cycle, explaining its importance, and Briefly touch on the process as a whole.\n",
      "2. Evaporation: Discuss the first stage of the water cycle - evaporation. Include information about the factors that speed up or slow down evaporation, visuals of water undergoing evaporation, and any relevant data or statistics.\n",
      "3. Condensation: Cover the second stage - condensation. Describe what happens to water vapor as it rises into the atmosphere and cools, resulting in clouds. You can include diagrams or images of water vapor rising and condensing.\n",
      "4. Precipitation: Discuss the third stage, precipitation. This is when water falls back to the earth's surface in the form of rain, snow or hail. You can provide visuals of different types of precipitation, examples of areas that receive precipitation, and how precipitation affects the environment.\n",
      "5. Collection and Runoff: Once the precipitation reaches the ground, it is collected either through runoff (water flows into rivers, streams, and lakes) or infiltration (water seeps into the soil and recharges groundwater). Create a section that explains the differences between runoff and infiltration, and their importance.\n",
      "6. Releases to Oceans: Finally, discuss the process of water returning to the ocean or other large bodies of water via rivers or streams. Mention any relevant data or statistics regarding the percentage of water that reaches the ocean or how the water cycle affects global water circulation.\n",
      "7. Conclusion: Summarize the main points and emphasize the importance of understanding the water cycle in our daily lives and the environment.\n",
      "8. Design and Layout: Make sure your infographic is visually appealing, easy to follow, and supports the information provided in the previous sections. Use images, graphics, and colors to make it engaging.\n",
      "9. Citations: Be sure to include any relevant references for further reading or research.\n",
      "\n",
      "Remember, your infographic should tell a story by making the information easy to understand, so keep your design simple, concise, and focus on the key points of the water cycle. Good luck with your project!</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset_from_csv(csv_files, split_labels)\n",
    "column_names = list(raw_datasets[\"train\"].features)\n",
    "\n",
    "print(f\"Training on the following splits: {[split + ' : ' + str(dset.num_rows) for split, dset in raw_datasets.items()]}\")\n",
    "\n",
    "raw_datasets = raw_datasets.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Formatting comparisons with prompt template\",\n",
    ")\n",
    "for split in [\"train\", \"test\"]:\n",
    "    raw_datasets[split] = raw_datasets[split].rename_columns(\n",
    "        {\"text_prompt\": \"prompt\", \"text_chosen\": \"chosen\", \"text_rejected\": \"rejected\"}\n",
    "    )\n",
    "\n",
    "for index in random.sample(range(len(raw_datasets[\"train\"])), 1):\n",
    "    print(f\"Prompt sample {index} of the raw training set:\\n\\n{raw_datasets['train'][index]['prompt']}\")\n",
    "    print(f\"Rejected sample {index} of the raw training set:\\n\\n{raw_datasets['train'][index]['rejected']}\")\n",
    "    print(f\"Chosen sample {index} of the raw training set:\\n\\n{raw_datasets['train'][index]['chosen']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9cafe9be-09c4-470f-8c65-0b83b59e08a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': model_init_kwargs, ref_model_init_kwargs, max_length, max_prompt_length, loss_type. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py:262: UserWarning: You passed `model_init_kwargs` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
      "  warnings.warn(\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py:287: UserWarning: You passed `ref_model_init_kwargs` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
      "  warnings.warn(\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py:312: UserWarning: You passed a model_id to the DPOTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
      "Model config MistralConfig {\n",
      "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/model.safetensors.index.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21a9f6af3034121bc21869bd5b97a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing MistralForCausalLM.\n",
      "\n",
      "All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py:319: UserWarning: You passed a ref model_id to the DPOTrainer. This will automatically create an `AutoModelForCausalLM`\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
      "Model config MistralConfig {\n",
      "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/model.safetensors.index.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bada67cd1c47b286f63536a7dff33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing MistralForCausalLM.\n",
      "\n",
      "All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /arc/home/obriaint/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py:469: UserWarning: You passed `max_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
      "  warnings.warn(\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py:475: UserWarning: You passed `max_prompt_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
      "  warnings.warn(\n",
      "/arc/home/obriaint/.local/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py:544: UserWarning: You passed `loss_type` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484bbf972eb5425da4aba698e810e61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt from train dataset:   0%|          | 0/324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28541dca60894fdb97f64e6fa50673db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49628b16d7e04ab196db60ac2a60434f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt from eval dataset:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0488e5db01c84dfe9165866c41adbb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6386bc2b4b54b77a9a19935e5a6a6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e726e25929d94810a7cfca6417ec421b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Using cpu_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = dict(revision='main',\n",
    "                    trust_remote_code=False,\n",
    "                    use_cache=False,\n",
    "                   token=hf_token)\n",
    "\n",
    "ref_model = pretrained_model_path\n",
    "ref_model_kwargs = model_kwargs\n",
    "\n",
    "#########################\n",
    "# Instantiate DPO trainer\n",
    "#########################\n",
    "trainer = DPOTrainer(\n",
    "    pretrained_model_path,\n",
    "    ref_model,\n",
    "    model_init_kwargs=model_kwargs,\n",
    "    ref_model_init_kwargs=ref_model_kwargs,\n",
    "    args=training_args,\n",
    "    beta=training_args.beta,\n",
    "    train_dataset=raw_datasets[\"train\"],\n",
    "    eval_dataset=raw_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=training_args.max_length,\n",
    "    max_prompt_length=training_args.max_prompt_length,\n",
    "    loss_type=training_args.loss_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234946d-63a9-4938-9db2-c6b6cd2b6efc",
   "metadata": {},
   "source": [
    "## Overview of the Training Iteration in DPO\n",
    "\n",
    "The **Direct Preference Optimization (DPO)** process fine-tunes a language model by comparing pairs of responses (chosen vs. rejected) to align the model's behavior with specific preferences. Each training iteration involves multiple steps, from data preprocessing to loss computation. Here's an overview of the key steps:\n",
    "\n",
    "1. **Tokenization of Inputs**:\n",
    "   - Converts raw text prompts, chosen responses, and rejected responses into token IDs suitable for input to the model.\n",
    "   - Handles padding and truncation to ensure uniform sequence lengths.\n",
    "\n",
    "2. **Preparation of Training Batches**:\n",
    "   - Dynamically pads sequences in the dataset to the maximum length within each batch.\n",
    "   - Concatenates chosen and rejected responses for efficient processing.\n",
    "\n",
    "3. **Forward Pass**:\n",
    "   - Computes the logits (output probabilities) for both chosen and rejected responses.\n",
    "   - Concatenates inputs for chosen and rejected responses to avoid separate forward passes.\n",
    "\n",
    "4. **Log Probability Computation**:\n",
    "   - Calculates log probabilities for chosen and rejected responses.\n",
    "   - Compares these to log probabilities from a reference model to compute the policy’s alignment with preferences.\n",
    "\n",
    "5. **DPO Loss Calculation**:\n",
    "   - Computes the DPO loss using chosen and rejected log probabilities.\n",
    "   - Incorporates hyperparameters such as the beta temperature to adjust the training dynamics.\n",
    "\n",
    "6. **Backpropagation and Optimization**:\n",
    "   - Uses the computed loss to adjust model weights via gradient descent.\n",
    "\n",
    "Below, each step is illustrated with code examples and explanations.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Tokenization of Inputs\n",
    "\n",
    "The `tokenize_row` function tokenizes a single dataset row, converting text prompts, chosen responses, and rejected responses into token IDs. Padding and truncation are applied as needed.\n",
    "\n",
    "- The `prompt`, `chosen`, and `rejected` fields in the sample are tokenized.\n",
    "- Truncation limits the length of sequences to `max_prompt_length` and `max_completion_length`.\n",
    "- The resulting dictionary contains tokenized IDs for each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26946ed6-8a51-4412-9de5-b4852a9d6865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prompt:\n",
      "\n",
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "Provide a comprehensive analysis of the factors leading to the American Civil Rights Movement.</s>\n",
      "\n",
      "\n",
      "Tokenized Prompt:\n",
      "\n",
      "[523, 28766, 6574, 28766, 28767, 13, 2, 13, 28789, 28766, 1838, 28766, 28767, 13, 18325, 547, 264, 15313, 5643, 302, 272, 8612, 5374, 298, 272, 2556, 12045, 12744, 25361, 28723, 2, 13]\n"
     ]
    }
   ],
   "source": [
    "indx = 0  # Example index in the dataset\n",
    "sample = trainer.train_dataset[indx]\n",
    "\n",
    "# Tokenize the sample\n",
    "tokenized_sample = trainer.tokenize_row(\n",
    "    sample,\n",
    "    processing_class=trainer.processing_class,\n",
    "    max_prompt_length=512,\n",
    "    max_completion_length=None, \n",
    "    add_special_tokens=False \n",
    ")\n",
    "\n",
    "print(f\"Original Prompt:\\n\\n{sample['prompt']}\")\n",
    "print(f\"\\nTokenized Prompt:\\n\\n{tokenized_sample['prompt_input_ids']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c840b-893e-47e9-bb8f-823695b919b3",
   "metadata": {},
   "source": [
    "### Step 2: Preparation of Training Batches\n",
    "\n",
    "The `PreferenceCollator` dynamically pads sequences to the maximum length within a batch to ensure uniformity. This is essential for efficient processing on hardware like GPUs.\n",
    "\n",
    "- Prompts, chosen responses, and rejected responses are padded with `pad_token_id`.\n",
    "- Attention masks indicate which tokens are real (1) or padding (0).\n",
    "- The padded batch ensures all sequences have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f1c8a4a-07b3-4c81-8a15-6611d3515e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding Value: 2\n",
      "\n",
      "\n",
      "Padded Batch:\n",
      "tensor([[    2,     2,     2,     2,     2,   523, 28766,  6574, 28766, 28767,\n",
      "            13,     2,    13, 28789, 28766,  1838, 28766, 28767,    13, 18325,\n",
      "           547,   264, 15313,  5643,   302,   272,  8612,  5374,   298,   272,\n",
      "          2556, 12045, 12744, 25361, 28723,     2,    13],\n",
      "        [  523, 28766,  6574, 28766, 28767,    13,     2,    13, 28789, 28766,\n",
      "          1838, 28766, 28767,    13, 18325,   547,   264, 10537, 13268,   302,\n",
      "           272,  1759,   302,  3601,  1098, 10840,  8679,   304,   871,  9545,\n",
      "           298,  3687,  2170, 10821, 28723,     2,    13]])\n"
     ]
    }
   ],
   "source": [
    "# Create a batch with two examples for demonstration\n",
    "batch = [trainer.train_dataset[0], trainer.train_dataset[1]]\n",
    "\n",
    "# Collate the batch\n",
    "padded_batch = trainer.data_collator(batch)\n",
    "\n",
    "print(f\"Padding Value: {trainer.padding_value}\")\n",
    "print(f\"\\n\\nPadded Batch:\\n{padded_batch['prompt_input_ids']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6046a-2afc-4c18-9df7-f6b29058febe",
   "metadata": {},
   "source": [
    "### Step 3: Forward Pass\n",
    "\n",
    "The **forward pass** in the `concatenated_forward` function is designed to efficiently compute model predictions for both chosen and rejected responses in a single operation. Here's how it works:\n",
    "\n",
    "1. **Concatenation of Inputs**:\n",
    "   - The prompts are repeated for both the chosen and rejected completions.\n",
    "   - Chosen and rejected completion tokens are padded to ensure uniform length.\n",
    "   - This enables simultaneous processing of both completions in the same forward pass, saving computation time.\n",
    "\n",
    "2. **Model Inference**:\n",
    "   - The concatenated inputs (`input_ids` and `attention_mask`) are passed to the model.\n",
    "   - The model outputs logits for each token in the sequences.\n",
    "\n",
    "3. **Alignment of Logits and Labels**:\n",
    "   - Logits are shifted to align with the labels for causal language modeling.\n",
    "   - Labels are adjusted to exclude the first token, aligning with the logits.\n",
    "\n",
    "4. **Loss Masking**:\n",
    "   - A mask is applied to ensure only completion tokens contribute to the loss.\n",
    "   - Tokens from the prompt or padding are ignored during the loss calculation.\n",
    "\n",
    "5. **Log Probability Calculation**:\n",
    "   - The logits are converted to log probabilities using `log_softmax`, which are then used to calculate the DPO loss.\n",
    "\n",
    "This process ensures that both chosen and rejected completions are processed efficiently while determining their contribution to the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "378dc947-4dd7-4bb6-a98a-db90757f59c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Outputs:\n",
      "Chosen Logits: tensor([-427.2798, -409.8966], grad_fn=<SumBackward1>)\n",
      "Rejected Logits: tensor([   0.0000, -421.8497], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "def forward(model, batch):\n",
    "    # Concatenate inputs for chosen and rejected completions\n",
    "    concatenated_batch = trainer.concatenated_inputs(batch, padding_value=trainer.padding_value)\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model(\n",
    "        input_ids=concatenated_batch[\"prompt_input_ids\"],\n",
    "        attention_mask=concatenated_batch[\"prompt_attention_mask\"],\n",
    "    )\n",
    "    logits = outputs.logits  # Raw model outputs (logits)\n",
    "    \n",
    "    # Adjust logits for causal language modeling by excluding the last token\n",
    "    logits = logits[:, :-1, :]  # Shape: [batch_size, seq_length - 1, vocab_size]\n",
    "    # Align labels with logits by truncating to the same sequence length\n",
    "    labels = concatenated_batch[\"completion_input_ids\"][:, :logits.size(1)]\n",
    "    \n",
    "    # Apply loss mask to exclude padding tokens from loss computation\n",
    "    loss_mask = concatenated_batch[\"completion_attention_mask\"][:, :logits.size(1)]\n",
    "    labels[~loss_mask] = 0  # Set labels corresponding to padding tokens to zero\n",
    "    \n",
    "    # Compute log probabilities\n",
    "    log_probs = logits.log_softmax(dim=-1)\n",
    "    \n",
    "    # Extract the log probabilities of the tokens in `labels`\n",
    "    per_token_log_probs = torch.gather(log_probs, dim=2, index=labels.unsqueeze(2)).squeeze(2)\n",
    "    per_token_log_probs[~loss_mask] = 0  # Exclude padding tokens\n",
    "    \n",
    "    # Summarize log probabilities for chosen and rejected completions\n",
    "    batch_size = concatenated_batch[\"prompt_input_ids\"].size(0) // 2\n",
    "    chosen_log_probs = per_token_log_probs[:batch_size].sum(dim=1)\n",
    "    rejected_log_probs = per_token_log_probs[batch_size:].sum(dim=1)\n",
    "    \n",
    "    # Create the output dictionary\n",
    "    output = {}\n",
    "    \n",
    "    # Compute the total log probabilities for each example\n",
    "    output[\"chosen_logps\"] = chosen_log_probs  # Log probabilities for chosen completions\n",
    "    output[\"rejected_logps\"] = rejected_log_probs  # Log probabilities for rejected completions\n",
    "\n",
    "    return output\n",
    "\n",
    "model_output = forward(trainer.model, padded_batch)\n",
    "\n",
    "print(\"Batch Outputs:\")\n",
    "print(f\"Chosen Logits: {model_output['chosen_logps']}\")\n",
    "print(f\"Rejected Logits: {model_output['rejected_logps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f939424-fe86-4f3e-a13a-c89398280ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ref_model_output = forward(trainer.ref_model, padded_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec903bda-06a7-47ec-810d-414edcb850d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326b3ff-8e61-4bbb-a4a6-5e700ddb728f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94ce0972-26f6-45b2-9a82-8d9f26a0b04b",
   "metadata": {},
   "source": [
    "### Step 4: DPO Loss Calculation\n",
    "\n",
    "The DPO loss is computed to align the policy model's predictions (log probabilities for chosen and rejected completions) with the preferences defined by a reference model. For the `sigmoid` loss:\n",
    "\n",
    "1. **Log Ratio Calculation**:\n",
    "   - Compute the difference between the log probabilities of the chosen and rejected completions (`chosen_logratios` and `rejected_logratios`) for both the target and reference models.\n",
    "   - Subtract the reference log probabilities unless the process is `reference_free`.\n",
    "\n",
    "2. **Logits**:\n",
    "   - Compute the logits as the difference between the chosen and rejected log ratios.\n",
    "\n",
    "3. **Loss Function**:\n",
    "   - Apply the `sigmoid` loss using `torch.nn.functional.logsigmoid` to encourage higher scores for chosen completions and lower scores for rejected completions.\n",
    "\n",
    "4. **Outputs**:\n",
    "   - Return the per-example loss, along with the chosen and rejected rewards.\n",
    "\n",
    "- The loss encourages the model to assign higher probabilities to chosen responses and lower probabilities to rejected ones.\n",
    "- Rewards measure how well the policy aligns with preferences.\n",
    "\n",
    "### **Explanation of Key Parameters**\n",
    "- **`beta`**: The temperature parameter scales the logits, typically a small value like `0.1` to `0.5`.\n",
    "- **`reference_free`**: If `True`, the reference model is not used, and the loss is computed solely based on the target model.\n",
    "\n",
    "### **Outputs**\n",
    "1. **`losses`**: Per-example DPO loss values.\n",
    "2. **`chosen_rewards`**: Rewards (scaled log probabilities) for chosen completions.\n",
    "3. **`rejected_rewards`**: Rewards (scaled log probabilities) for rejected completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa072e80-5940-4691-be57-e27805264fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "816b51b6-dad6-42e8-b19b-da39d0cdf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_logps = model_output['chosen_logps']\n",
    "rejected_logps = model_output['rejected_logps']\n",
    "ref_chosen_logps = ref_model_output['chosen_logps']\n",
    "ref_rejected_logps = ref_model_output['rejected_logps']\n",
    "\n",
    "\n",
    "logratios = chosen_logps - rejected_logps\n",
    "ref_logratios = ref_chosen_logps - ref_rejected_logps\n",
    "\n",
    "logratios = logratios\n",
    "ref_logratios = ref_logratios\n",
    "logits = logratios - ref_logratios\n",
    "\n",
    "losses = -torch.nn.functional.logsigmoid(trainer.beta * logits)\n",
    "\n",
    "chosen_rewards = trainer.beta * (chosen_logps - ref_chosen_logps).detach()\n",
    "rejected_rewards = trainer.beta * (rejected_logps - ref_rejected_logps).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a5e355b-b577-41b7-966d-c254d7aeae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: tensor([   nan, 0.6935], grad_fn=<NegBackward0>)\n",
      "Chosen Rewards: tensor([    nan, -0.0246])\n",
      "Rejected Rewards: tensor([ 0.0000, -0.0238])\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Losses:\", losses)\n",
    "print(\"Chosen Rewards:\", chosen_rewards)\n",
    "print(\"Rejected Rewards:\", rejected_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d46b07f4-25a3-4862-a472-6a99f8d74cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([      nan, -409.6503])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_chosen_logps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "32b7d1a6-47e5-4a54-94e9-69611e5b8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_accuracies = (chosen_rewards > rejected_rewards).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "26f05863-34bd-4445-891b-2d882e439448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7886f-0458-4a5c-8bff-ce5e49f0dfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27a180e2-91db-41c7-952c-7ab012df847b",
   "metadata": {},
   "source": [
    "### Step 6: Backpropagation and Optimization\n",
    "\n",
    "The loss is backpropagated, and the optimizer updates model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b42587b-38b3-4024-b4ee-f723228eb98a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m loss \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      3\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m()  \u001b[38;5;66;03m# Update model weights\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trainer\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization step completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'step'"
     ]
    }
   ],
   "source": [
    "# Simulate a single optimization step\n",
    "loss = losses.mean()\n",
    "loss.backward()  # Compute gradients\n",
    "trainer.optimizer.step()  # Update model weights\n",
    "trainer.optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "print(\"Optimization step completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d92cb-b5fe-45f0-975a-9c02a2ecf493",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "All of these steps are done by the `DPOTrainer.train()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfccd89-42f0-43c3-9cab-60599e61fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "metrics = train_result.metrics\n",
    "metrics[\"train_samples\"] = len(raw_datasets[\"train\"])\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
