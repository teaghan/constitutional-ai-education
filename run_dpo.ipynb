{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dgcs8doG-gog"
   },
   "source": [
    "# Direct Preference Optimization (DPO) Training\n",
    "\n",
    "This notebook demonstrates the second stage of our model improvement process: Direct Preference Optimization (DPO). After our initial Supervised Fine-tuning (SFT), DPO helps refine our model's ability to generate high-quality educational responses.\n",
    "\n",
    "## What is DPO?\n",
    "\n",
    "DPO is an advanced fine-tuning technique that teaches models to prefer certain types of outputs over others. Unlike traditional supervised learning where we provide a single \"correct\" answer, DPO learns from pairs of responses where one is preferred over the other. In our educational context, this means:\n",
    "\n",
    "1. **Learning from Comparisons**: The model learns which response characteristics are more effective for teaching\n",
    "2. **Preference-Based Training**: Instead of binary right/wrong labels, we use \"better/worse\" comparisons\n",
    "3. **Efficient Learning**: DPO is more sample-efficient than traditional reinforcement learning approaches\n",
    "\n",
    "### Our Application\n",
    "\n",
    "We're using DPO to further refine our SFT-trained model by teaching it to:\n",
    "- Prefer responses that encourage critical thinking over those that simply provide answers\n",
    "- Choose explanations that build connections to broader concepts\n",
    "- Generate responses that scaffold learning appropriately\n",
    "- Avoid overly directive or answer-revealing responses\n",
    "\n",
    "The training data comes from our dataset (generated in `generate_datasets.ipynb`) where we have:\n",
    "- **Original prompts**: The student questions or tasks\n",
    "- **Chosen responses**: The improved, pedagogically sound responses\n",
    "- **Rejected responses**: The initial responses that could be improved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5Rs1Fd6vU2JV"
   },
   "outputs": [],
   "source": [
    "#@title Colab Extra Install { display-mode: \"form\" }\n",
    "%%capture\n",
    "import os\n",
    "\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "\n",
    "    # Data directory\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    wrk_dir = '/content/drive/MyDrive/constitutional-ai-education'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqJUbJyK-_k0"
   },
   "source": [
    "## Training Configuration\n",
    "\n",
    "Our DPO training setup requires configuration to effectively learn the preferred responses to improve its ability to support students:\n",
    "\n",
    "### Model Configuration\n",
    "- **Base Model**: Llama 3.2 (1B parameter version)\n",
    "  - We start with our SFT-trained model from the previous stage\n",
    "  - Quantized to 4-bit for memory efficiency\n",
    "\n",
    "### DPO-Specific Parameters\n",
    "- **Beta**: 0.1\n",
    "  - Controls how strongly the model prefers the chosen response over the rejected one\n",
    "  - Lower values (like 0.1) lead to more conservative learning\n",
    "  - Higher values might cause the model to become too extreme in its preferences\n",
    "\n",
    "### Training Parameters\n",
    "- **Batch Size and Accumulation**:\n",
    "  - Small batch size (2) with gradient accumulation (4 steps)\n",
    "  - Effectively processes 8 examples per update\n",
    "  - Balances memory constraints with stable training\n",
    "\n",
    "### Memory Optimization\n",
    "- **4-bit Quantization**:\n",
    "  - Enables training on consumer hardware\n",
    "  - Maintains model quality while reducing memory usage\n",
    "- **Gradient Checkpointing**:\n",
    "  - Trades computation for memory efficiency\n",
    "  - Essential for training larger models on limited hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4tkX8DkUEM5",
    "outputId": "fdbde845-e12d-4e4a-f043-9800446a3fb6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel, is_bfloat16_supported, PatchDPOTrainer, FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template, standardize_data_formats\n",
    "import os\n",
    "import torch\n",
    "from dataclasses import dataclass, field\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from peft import PeftModel, prepare_model_for_kbit_training\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"Arguments for model configuration\"\"\"\n",
    "    model_name: str = \"unsloth/Llama-3.2-1B-bnb-4bit\"\n",
    "    sft_model_path: str = os.path.join(wrk_dir, \"models/Llama-3.2-1B-sft-edu\")\n",
    "    max_seq_length: int = 2048\n",
    "    # LoRA configuration\n",
    "    lora_r: int = 8\n",
    "    lora_alpha: int = 8\n",
    "    lora_dropout: float = 0\n",
    "    lora_bias: str = \"none\"\n",
    "    # Model loading configuration\n",
    "    load_in_4bit: bool = True\n",
    "    load_in_8bit: bool = False\n",
    "    full_finetuning: bool = False\n",
    "\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    \"\"\"Arguments for data processing\"\"\"\n",
    "    train_file: str = os.path.join(wrk_dir, \"data/train_dataset.csv\")\n",
    "    validation_file: str = os.path.join(wrk_dir, \"data/val_dataset.csv\")\n",
    "    preprocessing_num_workers: int = 4\n",
    "    chat_template: str = \"llama-3\"\n",
    "\n",
    "class DPOArguments:\n",
    "    \"\"\"DPO-specific training arguments\"\"\"\n",
    "    def __init__(self):\n",
    "        self.beta = 0.1\n",
    "        self.max_prompt_length = 512\n",
    "        self.max_length = 1024\n",
    "        self.dpo_config = DPOConfig(\n",
    "                            model_adapter_name=\"train_model\",\n",
    "                            ref_adapter_name=\"reference\",\n",
    "                            per_device_train_batch_size = 2,\n",
    "                            gradient_accumulation_steps = 4,\n",
    "                            warmup_ratio = 0.1,\n",
    "                            num_train_epochs = 3,\n",
    "                            learning_rate = 5e-6,\n",
    "                            fp16 = not is_bfloat16_supported(),\n",
    "                            bf16 = is_bfloat16_supported(),\n",
    "                            logging_steps = 1,\n",
    "                            optim = \"adamw_8bit\",\n",
    "                            weight_decay = 0.0,\n",
    "                            lr_scheduler_type = \"linear\",\n",
    "                            seed = 3407,\n",
    "                            output_dir = os.path.join(wrk_dir,'models/gemma-3-4b-dpo'),\n",
    "                            report_to = \"none\")\n",
    "\n",
    "# Initialize arguments with default values\n",
    "model_args = ModelArguments()\n",
    "data_args = DataArguments()\n",
    "training_args = DPOArguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH6dU8ndAzf7"
   },
   "source": [
    "## Model Setup for Preference Learning\n",
    "\n",
    "Before we can train our model to learn from preferences, we need to set it up carefully. This involves several steps:\n",
    "\n",
    "### 1. Loading the Base Model\n",
    "First, we load Llama with special optimizations:\n",
    "```python\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(...)\n",
    "```\n",
    "- We use Unsloth's optimized loading for better performance\n",
    "- The model is loaded in 4-bit format to save memory\n",
    "- We set a maximum sequence length to handle our educational responses\n",
    "\n",
    "### 2. Configuring Memory-Efficient Settings\n",
    "```python\n",
    "bnb_config = BitsAndBytesConfig(...)\n",
    "```\n",
    "We set up special memory settings using BitsAndBytes:\n",
    "- 4-bit quantization compresses the model\n",
    "- \"Double quantization\" saves even more memory\n",
    "- NF4 (normalized float 4) format works best for language models\n",
    "- We use bfloat16/float16 for calculations, depending on what your GPU supports\n",
    "\n",
    "### 3. Preparing for Training\n",
    "```python\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "```\n",
    "- We prepare the model specifically for training with quantization\n",
    "- Turn off caching to save memory during training\n",
    "- Set up the tokenizer to properly handle conversations using Llama's chat format\n",
    "\n",
    "### 4. Adding Our Educational Fine-tuning\n",
    "\n",
    "We load two copies of our educational training:\n",
    "\n",
    "```python\n",
    "model = PeftModel.from_pretrained(...)\n",
    "model.load_adapter(...)\n",
    "```\n",
    "\n",
    "1. **Training Adapter** (\"train_model\"):\n",
    "   - Contains what the model learned during SFT (Supervised Fine-Tuning)\n",
    "   - Will be updated as the model learns better teaching preferences\n",
    "   - Marked as trainable so it can be modified\n",
    "\n",
    "2. **Reference Adapter** (\"reference\"):\n",
    "   - Exact same copy of the SFT training\n",
    "   - Stays frozen (unchanged) during training\n",
    "   - Helps prevent the model from becoming too extreme in its changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "gaJEXeIaBBmM",
    "outputId": "25b055ba-544f-46f6-ac1d-787ffe9b2243"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6db79cb7bb3d47c4975311b28551b32a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "feaf96308b3e4b48873344170dddee0d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d8092e7714a4bcc96bd73f9a900ed07"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57d6c688ce2f46228e0e8b7a6d8317eb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ef73988dc71413ca500fbd1fbff78a3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Load model and tokenizer with Unsloth optimizations\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_args.model_name,\n",
    "    max_seq_length=model_args.max_seq_length,\n",
    "    load_in_4bit=model_args.load_in_4bit,\n",
    "    dtype=None,\n",
    "    full_finetuning=model_args.full_finetuning,\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=model_args.load_in_4bit,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 if is_bfloat16_supported() else torch.float16,\n",
    ")\n",
    "\n",
    "# Load base model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_args.model_name,\n",
    "    load_in_4bit=model_args.load_in_4bit,\n",
    "    quantization_config=bnb_config,\n",
    "    max_seq_length=model_args.max_seq_length\n",
    ")\n",
    "\n",
    "# Prepare for k-bit training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Configure tokenizer with appropriate chat template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=data_args.chat_template\n",
    ")\n",
    "\n",
    "# Load the adapter from the SFT fine-tuning stage\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    model_args.sft_model_path,\n",
    "    is_trainable=True,\n",
    "    adapter_name=training_args.dpo_config.model_adapter_name,\n",
    ")\n",
    "# Load the adapter a second time, with a different name, which will be our reference model.\n",
    "model.load_adapter(model_args.sft_model_path, adapter_name=training_args.dpo_config.ref_adapter_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IyPKlooyLpk"
   },
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "DPO requires structured data to learn preferences effectively:\n",
    "\n",
    "### Data Format\n",
    "Each training example contains:\n",
    "1. **Prompt**: The original student question or task\n",
    "2. **Chosen Response**: The pedagogically improved response\n",
    "3. **Rejected Response**: The initial, less optimal response\n",
    "\n",
    "### Why This Format Matters\n",
    "- Helps the model learn which response characteristics are preferred\n",
    "- Maintains context of the original student question\n",
    "- Enables the model to understand why certain responses are better\n",
    "\n",
    "### Processing Steps\n",
    "1. Load the SFT dataset containing original and improved responses\n",
    "2. Format conversations using the Llama chat template\n",
    "3. Create paired examples for preference learning\n",
    "4. Apply appropriate tokenization and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "suaJhgFl6W6R",
    "outputId": "b56e6251-b58d-4fbc-fbda-88f33fcd7f78"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Applying chat template (num_proc=4):   0%|          | 0/291 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49bc07b982fc42c994b780b2f0e6e77f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Applying chat template (num_proc=4):   0%|          | 0/37 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "773477b23ef944a28e5df012d7105dcf"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from trl import apply_chat_template\n",
    "\n",
    "def prepare_dpo_dataset(df):\n",
    "    \"\"\"Convert dataframe rows to message-based format expected by DPO processing\"\"\"\n",
    "    formatted_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Ensure strings and handle potential NaN values\n",
    "        prompt = str(row['init_prompt']) if pd.notna(row['init_prompt']) else \"\"\n",
    "        chosen = str(row['revision_response']) if pd.notna(row['revision_response']) else \"\"\n",
    "        rejected = str(row['init_response']) if pd.notna(row['init_response']) else \"\"\n",
    "\n",
    "        # Create the preference dataset format\n",
    "        formatted_data.append({\n",
    "            \"prompt\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"chosen\": [{\"role\": \"assistant\", \"content\": chosen}],\n",
    "            \"rejected\": [{\"role\": \"assistant\", \"content\": rejected}]\n",
    "        })\n",
    "    return formatted_data\n",
    "\n",
    "def load_datasets(data_args):\n",
    "    # Load dataframes\n",
    "    train_dataset = pd.read_csv(data_args.train_file)\n",
    "    eval_dataset = pd.read_csv(data_args.validation_file)\n",
    "\n",
    "    # Convert to message format\n",
    "    train_dataset = prepare_dpo_dataset(train_dataset)\n",
    "    eval_dataset = prepare_dpo_dataset(eval_dataset)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = Dataset.from_list(train_dataset)\n",
    "    eval_dataset = Dataset.from_list(eval_dataset)\n",
    "\n",
    "    # Combine into DatasetDict\n",
    "    raw_datasets = DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        \"test\": eval_dataset\n",
    "    })\n",
    "\n",
    "    # Apply chat template using TRL's helper function\n",
    "    datasets = raw_datasets.map(\n",
    "        lambda x: apply_chat_template(x, tokenizer),\n",
    "        remove_columns=raw_datasets[\"train\"].column_names,\n",
    "        num_proc=4,\n",
    "        desc=\"Applying chat template\"\n",
    "    )\n",
    "\n",
    "    # The datasets are now ready for the DPOTrainer\n",
    "    return datasets\n",
    "\n",
    "datasets = load_datasets(data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "chpRuGNjxHw6",
    "outputId": "e0e6da31-4b2c-45df-e3e0-e45f440ede8f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n'\n",
      " '\\n'\n",
      " 'Solve this equation and show me the answer: 3x + 7 = '\n",
      " '22.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n'\n",
      " '\\n')\n",
      "('Okay, letâ€™s solve the equation 3x + 7 = 22!\\n'\n",
      " '\\n'\n",
      " 'First, we need to get â€˜xâ€™ by itself. Letâ€™s subtract 7 from both sides â€“ what '\n",
      " 'do you think happens when we do that? (Pause briefly to let the student '\n",
      " 'respond).  That gives us 3x = 15. Now, whatâ€™s the next step to find out what '\n",
      " 'â€˜xâ€™ actually *is*?  Think about how many times 3 goes into 15.  Could you '\n",
      " 'write that out? (Encourage them to show their work).  Youâ€™ll find that x '\n",
      " 'equals 5!\\n'\n",
      " '\\n'\n",
      " 'Now, thatâ€™s the answer, but letâ€™s check it out.  Go back to the original '\n",
      " 'equation, 3x + 7 = 22, and plug in 5 for â€˜xâ€™. Does it work? (Pause for '\n",
      " 'student to verify).  Great!\\n'\n",
      " '\\n'\n",
      " 'Here are a few things to think about: What if the number on the right side '\n",
      " 'of the equation (the â€˜22â€™) was different? How would that change the steps we '\n",
      " 'took to solve for â€˜xâ€™? Could we create our own equations with similar steps? '\n",
      " 'Maybe try changing the 7 to a different number and seeing what happens? Or, '\n",
      " 'what if we had a more complex equation with fractions or decimals? How would '\n",
      " 'we adjust our approach then?<|eot_id|>')\n",
      "(\"Okay, let's solve the equation 3x + 7 = 22:\\n\"\n",
      " '\\n'\n",
      " \"**1. Isolate the term with 'x':**\\n\"\n",
      " '\\n'\n",
      " '   Subtract 7 from both sides of the equation:\\n'\n",
      " '   3x + 7 - 7 = 22 - 7\\n'\n",
      " '   3x = 15\\n'\n",
      " '\\n'\n",
      " \"**2. Solve for 'x':**\\n\"\n",
      " '\\n'\n",
      " '   Divide both sides by 3:\\n'\n",
      " '   3x / 3 = 15 / 3\\n'\n",
      " '   x = 5\\n'\n",
      " '\\n'\n",
      " '**Solution:**\\n'\n",
      " '\\n'\n",
      " 'Therefore, x = 5\\n'\n",
      " '\\n'\n",
      " '**Answer: x = 5**<|eot_id|>')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "row = datasets['train'][0]\n",
    "pprint.pprint(row[\"prompt\"])\n",
    "pprint.pprint(row[\"chosen\"])\n",
    "pprint.pprint(row[\"rejected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "eZb_StKXoUo_",
    "outputId": "2f3d2af6-7fb1-403e-c1dd-1aa1976fd577"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Extracting prompt in train dataset (num_proc=2):   0%|          | 0/291 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbf0114dcd294c55882f16d07a6cb643"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Applying chat template to train dataset (num_proc=2):   0%|          | 0/291 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdb981b38634472ca291da0eddf2dca5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Tokenizing train dataset (num_proc=2):   0%|          | 0/291 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b9764603e7c49ada5a518506b50ba96"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Extracting prompt in eval dataset (num_proc=2):   0%|          | 0/37 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c76a20f1e1944269860e9d8bc7fd10de"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Applying chat template to eval dataset (num_proc=2):   0%|          | 0/37 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d532fc9e35c3467c897f30ee0b3a1d09"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Tokenizing eval dataset (num_proc=2):   0%|          | 0/37 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ae8bb56be1f41859aa18caf0fe67f3b"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "PatchDPOTrainer()\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model = model,\n",
    "    args = training_args.dpo_config,\n",
    "    beta = training_args.beta,\n",
    "    train_dataset = datasets['train'],\n",
    "    eval_dataset = datasets['test'],\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = training_args.max_length,\n",
    "    max_prompt_length = training_args.max_prompt_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "imccFTEubfCZ",
    "outputId": "3f0279d9-6ab8-4a85-e86d-992512e54581"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 291 | Num Epochs = 3 | Total steps = 108\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 5,636,096/1,000,000,000 (0.56% trained)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 18:11, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>rewards / chosen</th>\n",
       "      <th>rewards / rejected</th>\n",
       "      <th>rewards / accuracies</th>\n",
       "      <th>rewards / margins</th>\n",
       "      <th>logps / chosen</th>\n",
       "      <th>logps / rejected</th>\n",
       "      <th>logits / chosen</th>\n",
       "      <th>logits / rejected</th>\n",
       "      <th>eval_logits / chosen</th>\n",
       "      <th>eval_logits / rejected</th>\n",
       "      <th>nll_loss</th>\n",
       "      <th>aux_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-995.037292</td>\n",
       "      <td>-1251.572510</td>\n",
       "      <td>0.219984</td>\n",
       "      <td>0.090849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-970.040710</td>\n",
       "      <td>-978.204468</td>\n",
       "      <td>0.654421</td>\n",
       "      <td>0.837312</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.685800</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>-1274.478882</td>\n",
       "      <td>-1199.594482</td>\n",
       "      <td>-0.189422</td>\n",
       "      <td>-0.296710</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.691100</td>\n",
       "      <td>-0.001135</td>\n",
       "      <td>-0.005249</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>-918.644897</td>\n",
       "      <td>-910.278381</td>\n",
       "      <td>-0.008415</td>\n",
       "      <td>0.141742</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.685700</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>-0.009537</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.015069</td>\n",
       "      <td>-1227.593262</td>\n",
       "      <td>-1427.447266</td>\n",
       "      <td>-0.117358</td>\n",
       "      <td>-0.403698</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.683800</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>-0.009696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018906</td>\n",
       "      <td>-1098.032471</td>\n",
       "      <td>-1251.532349</td>\n",
       "      <td>0.394746</td>\n",
       "      <td>0.532322</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.668500</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>-0.034704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049926</td>\n",
       "      <td>-1099.028442</td>\n",
       "      <td>-1292.878418</td>\n",
       "      <td>0.207931</td>\n",
       "      <td>-0.298634</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>-0.007064</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.022858</td>\n",
       "      <td>-1278.541992</td>\n",
       "      <td>-1631.342773</td>\n",
       "      <td>0.468701</td>\n",
       "      <td>0.515837</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.674800</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>-0.016894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037221</td>\n",
       "      <td>-1333.130249</td>\n",
       "      <td>-1403.849121</td>\n",
       "      <td>0.107704</td>\n",
       "      <td>-0.023202</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>-0.049842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>-1106.678223</td>\n",
       "      <td>-1211.460815</td>\n",
       "      <td>0.475424</td>\n",
       "      <td>0.277084</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>0.048843</td>\n",
       "      <td>-0.038745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087588</td>\n",
       "      <td>-1230.658447</td>\n",
       "      <td>-1442.200195</td>\n",
       "      <td>0.469971</td>\n",
       "      <td>-0.295803</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.048190</td>\n",
       "      <td>-0.110436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.158627</td>\n",
       "      <td>-1305.923340</td>\n",
       "      <td>-1475.805054</td>\n",
       "      <td>0.071997</td>\n",
       "      <td>-0.280839</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.654500</td>\n",
       "      <td>0.012287</td>\n",
       "      <td>-0.067496</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.079783</td>\n",
       "      <td>-942.348083</td>\n",
       "      <td>-987.421448</td>\n",
       "      <td>0.073223</td>\n",
       "      <td>0.103173</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.626200</td>\n",
       "      <td>0.059007</td>\n",
       "      <td>-0.082239</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.141246</td>\n",
       "      <td>-790.112793</td>\n",
       "      <td>-632.407654</td>\n",
       "      <td>0.154987</td>\n",
       "      <td>-0.209350</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.647800</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>-0.079266</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.094528</td>\n",
       "      <td>-1123.544067</td>\n",
       "      <td>-902.911011</td>\n",
       "      <td>0.293139</td>\n",
       "      <td>0.152149</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.612400</td>\n",
       "      <td>0.027020</td>\n",
       "      <td>-0.145480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>-1192.108521</td>\n",
       "      <td>-1256.018066</td>\n",
       "      <td>-0.073033</td>\n",
       "      <td>-0.124341</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.077404</td>\n",
       "      <td>-0.231992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.309395</td>\n",
       "      <td>-1145.566406</td>\n",
       "      <td>-1374.114746</td>\n",
       "      <td>0.214910</td>\n",
       "      <td>0.028655</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.607400</td>\n",
       "      <td>0.053752</td>\n",
       "      <td>-0.127490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181242</td>\n",
       "      <td>-709.278381</td>\n",
       "      <td>-868.145020</td>\n",
       "      <td>0.310635</td>\n",
       "      <td>-0.145673</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>-0.249514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>-1177.613037</td>\n",
       "      <td>-1335.463623</td>\n",
       "      <td>0.053611</td>\n",
       "      <td>-0.129962</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.633100</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>-0.126046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127295</td>\n",
       "      <td>-1194.478516</td>\n",
       "      <td>-1301.377930</td>\n",
       "      <td>0.047041</td>\n",
       "      <td>-0.101719</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.568100</td>\n",
       "      <td>0.066657</td>\n",
       "      <td>-0.215293</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.281950</td>\n",
       "      <td>-976.948120</td>\n",
       "      <td>-1060.051270</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>-0.293568</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>0.080865</td>\n",
       "      <td>-0.306200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.387065</td>\n",
       "      <td>-856.151611</td>\n",
       "      <td>-812.705261</td>\n",
       "      <td>-0.230335</td>\n",
       "      <td>-0.558941</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>0.111234</td>\n",
       "      <td>-0.299824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411058</td>\n",
       "      <td>-1187.239868</td>\n",
       "      <td>-1384.159424</td>\n",
       "      <td>0.088465</td>\n",
       "      <td>0.372868</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.515900</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>-0.323476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.405583</td>\n",
       "      <td>-1144.946655</td>\n",
       "      <td>-1368.957520</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>-0.081163</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.551200</td>\n",
       "      <td>0.093514</td>\n",
       "      <td>-0.231032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.324546</td>\n",
       "      <td>-899.207031</td>\n",
       "      <td>-1012.064209</td>\n",
       "      <td>0.135921</td>\n",
       "      <td>0.248782</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>-0.377245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406086</td>\n",
       "      <td>-965.798889</td>\n",
       "      <td>-905.314941</td>\n",
       "      <td>0.287925</td>\n",
       "      <td>0.181434</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.513500</td>\n",
       "      <td>0.072881</td>\n",
       "      <td>-0.337127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410008</td>\n",
       "      <td>-905.313843</td>\n",
       "      <td>-868.963440</td>\n",
       "      <td>0.439770</td>\n",
       "      <td>0.354220</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.532400</td>\n",
       "      <td>0.071307</td>\n",
       "      <td>-0.308790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380098</td>\n",
       "      <td>-1216.398315</td>\n",
       "      <td>-1307.812134</td>\n",
       "      <td>0.079647</td>\n",
       "      <td>-0.136184</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.114244</td>\n",
       "      <td>-0.468460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.582705</td>\n",
       "      <td>-744.423950</td>\n",
       "      <td>-794.839600</td>\n",
       "      <td>-0.274114</td>\n",
       "      <td>-0.248457</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.078807</td>\n",
       "      <td>-0.523465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602272</td>\n",
       "      <td>-1121.177002</td>\n",
       "      <td>-1384.962769</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>0.044279</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.433300</td>\n",
       "      <td>0.138786</td>\n",
       "      <td>-0.518173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656959</td>\n",
       "      <td>-1134.969604</td>\n",
       "      <td>-1199.114868</td>\n",
       "      <td>0.183801</td>\n",
       "      <td>-0.356676</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.486900</td>\n",
       "      <td>0.094731</td>\n",
       "      <td>-0.409178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.503909</td>\n",
       "      <td>-1314.880859</td>\n",
       "      <td>-1521.201904</td>\n",
       "      <td>0.227611</td>\n",
       "      <td>-0.074759</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.488900</td>\n",
       "      <td>-0.025915</td>\n",
       "      <td>-0.522243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.496329</td>\n",
       "      <td>-1271.050781</td>\n",
       "      <td>-1440.804688</td>\n",
       "      <td>0.202452</td>\n",
       "      <td>0.202264</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.403600</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>-0.656299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726585</td>\n",
       "      <td>-1113.143433</td>\n",
       "      <td>-1240.185791</td>\n",
       "      <td>-0.078400</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.096472</td>\n",
       "      <td>-0.545706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642178</td>\n",
       "      <td>-901.154663</td>\n",
       "      <td>-943.272461</td>\n",
       "      <td>-0.129086</td>\n",
       "      <td>-0.324079</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>-0.563212</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.572910</td>\n",
       "      <td>-1120.098389</td>\n",
       "      <td>-1008.998535</td>\n",
       "      <td>0.143142</td>\n",
       "      <td>-0.171946</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>-0.044238</td>\n",
       "      <td>-0.723987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679749</td>\n",
       "      <td>-1123.342529</td>\n",
       "      <td>-1130.578857</td>\n",
       "      <td>0.101895</td>\n",
       "      <td>0.104026</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.399400</td>\n",
       "      <td>0.081191</td>\n",
       "      <td>-0.663095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744286</td>\n",
       "      <td>-1060.472412</td>\n",
       "      <td>-1039.909546</td>\n",
       "      <td>0.145998</td>\n",
       "      <td>-0.111435</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>0.150539</td>\n",
       "      <td>-0.731364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881903</td>\n",
       "      <td>-979.834106</td>\n",
       "      <td>-904.859009</td>\n",
       "      <td>0.117631</td>\n",
       "      <td>-0.046401</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.358100</td>\n",
       "      <td>0.226485</td>\n",
       "      <td>-0.711728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938213</td>\n",
       "      <td>-1046.273560</td>\n",
       "      <td>-1232.034302</td>\n",
       "      <td>0.192013</td>\n",
       "      <td>-0.389450</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.352700</td>\n",
       "      <td>0.185042</td>\n",
       "      <td>-0.701320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886362</td>\n",
       "      <td>-1079.388794</td>\n",
       "      <td>-1168.440430</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>-0.414583</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>0.270642</td>\n",
       "      <td>-0.722100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992741</td>\n",
       "      <td>-1286.260864</td>\n",
       "      <td>-1551.880371</td>\n",
       "      <td>-0.248179</td>\n",
       "      <td>-0.654294</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.249136</td>\n",
       "      <td>-0.856018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.105154</td>\n",
       "      <td>-1057.121582</td>\n",
       "      <td>-1161.446777</td>\n",
       "      <td>0.105955</td>\n",
       "      <td>-0.116198</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.181119</td>\n",
       "      <td>-0.721779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902897</td>\n",
       "      <td>-1021.204895</td>\n",
       "      <td>-1305.736694</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>-0.374224</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>-0.961329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.012945</td>\n",
       "      <td>-1018.180054</td>\n",
       "      <td>-774.822998</td>\n",
       "      <td>0.173080</td>\n",
       "      <td>0.489132</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>-0.028624</td>\n",
       "      <td>-1.277625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.249001</td>\n",
       "      <td>-1459.706299</td>\n",
       "      <td>-1555.225708</td>\n",
       "      <td>-0.420425</td>\n",
       "      <td>-0.236855</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>0.070804</td>\n",
       "      <td>-0.894778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965582</td>\n",
       "      <td>-1226.428589</td>\n",
       "      <td>-1673.824707</td>\n",
       "      <td>0.061619</td>\n",
       "      <td>-0.009404</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.266400</td>\n",
       "      <td>0.185311</td>\n",
       "      <td>-1.124161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.309472</td>\n",
       "      <td>-988.961914</td>\n",
       "      <td>-963.075806</td>\n",
       "      <td>0.056031</td>\n",
       "      <td>0.389761</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>0.064471</td>\n",
       "      <td>-0.810748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875219</td>\n",
       "      <td>-1203.316406</td>\n",
       "      <td>-990.416992</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>-0.088477</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.304700</td>\n",
       "      <td>0.124579</td>\n",
       "      <td>-1.018425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.143004</td>\n",
       "      <td>-948.580505</td>\n",
       "      <td>-1090.563965</td>\n",
       "      <td>-0.104981</td>\n",
       "      <td>-0.062880</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.385600</td>\n",
       "      <td>0.078432</td>\n",
       "      <td>-0.792841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871273</td>\n",
       "      <td>-698.977966</td>\n",
       "      <td>-711.948059</td>\n",
       "      <td>0.506080</td>\n",
       "      <td>0.617155</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.453600</td>\n",
       "      <td>-0.112715</td>\n",
       "      <td>-0.801600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.688885</td>\n",
       "      <td>-925.420349</td>\n",
       "      <td>-948.589600</td>\n",
       "      <td>-0.157394</td>\n",
       "      <td>-0.140509</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.369200</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>-0.794901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849618</td>\n",
       "      <td>-1161.419800</td>\n",
       "      <td>-1369.912231</td>\n",
       "      <td>0.451192</td>\n",
       "      <td>0.616666</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.038023</td>\n",
       "      <td>-0.984691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.022713</td>\n",
       "      <td>-1221.700562</td>\n",
       "      <td>-1513.825928</td>\n",
       "      <td>-0.037234</td>\n",
       "      <td>-0.234788</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>0.200005</td>\n",
       "      <td>-0.490190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>-921.371643</td>\n",
       "      <td>-896.211487</td>\n",
       "      <td>0.387401</td>\n",
       "      <td>0.614483</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>-0.797374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>-1320.812378</td>\n",
       "      <td>-1248.427246</td>\n",
       "      <td>0.067338</td>\n",
       "      <td>0.198761</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>0.081883</td>\n",
       "      <td>-0.859438</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.941321</td>\n",
       "      <td>-1105.352905</td>\n",
       "      <td>-1118.092407</td>\n",
       "      <td>0.202740</td>\n",
       "      <td>-0.167704</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.275700</td>\n",
       "      <td>0.263407</td>\n",
       "      <td>-1.029353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.292760</td>\n",
       "      <td>-1271.910767</td>\n",
       "      <td>-1605.957275</td>\n",
       "      <td>-0.210405</td>\n",
       "      <td>-0.572151</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.270964</td>\n",
       "      <td>-0.786605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.057569</td>\n",
       "      <td>-986.597351</td>\n",
       "      <td>-1132.319702</td>\n",
       "      <td>0.388767</td>\n",
       "      <td>0.123591</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.237272</td>\n",
       "      <td>-0.812509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.049780</td>\n",
       "      <td>-894.948303</td>\n",
       "      <td>-873.559387</td>\n",
       "      <td>-0.107423</td>\n",
       "      <td>-0.091111</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.216663</td>\n",
       "      <td>-1.504031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.720695</td>\n",
       "      <td>-1166.540771</td>\n",
       "      <td>-1754.730469</td>\n",
       "      <td>0.057276</td>\n",
       "      <td>-0.222584</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.153222</td>\n",
       "      <td>-0.689378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842600</td>\n",
       "      <td>-1196.890137</td>\n",
       "      <td>-1333.565674</td>\n",
       "      <td>0.392854</td>\n",
       "      <td>0.316775</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.254500</td>\n",
       "      <td>-0.235663</td>\n",
       "      <td>-1.649374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.413711</td>\n",
       "      <td>-1235.776123</td>\n",
       "      <td>-1277.372925</td>\n",
       "      <td>-0.491246</td>\n",
       "      <td>-0.552699</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.488700</td>\n",
       "      <td>-0.099818</td>\n",
       "      <td>-0.586579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486761</td>\n",
       "      <td>-911.634705</td>\n",
       "      <td>-556.085938</td>\n",
       "      <td>0.041090</td>\n",
       "      <td>0.373753</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.283365</td>\n",
       "      <td>-1.434908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.718273</td>\n",
       "      <td>-1118.293823</td>\n",
       "      <td>-1532.675415</td>\n",
       "      <td>0.167643</td>\n",
       "      <td>-0.187905</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>0.223335</td>\n",
       "      <td>-1.369503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.592837</td>\n",
       "      <td>-1189.064941</td>\n",
       "      <td>-1302.321777</td>\n",
       "      <td>-0.401261</td>\n",
       "      <td>-0.678822</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.198517</td>\n",
       "      <td>-1.319772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.518289</td>\n",
       "      <td>-1140.770264</td>\n",
       "      <td>-1276.221069</td>\n",
       "      <td>0.418240</td>\n",
       "      <td>0.212339</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.246636</td>\n",
       "      <td>-0.772802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.019438</td>\n",
       "      <td>-1015.396729</td>\n",
       "      <td>-1469.893799</td>\n",
       "      <td>0.031664</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.429800</td>\n",
       "      <td>-0.064830</td>\n",
       "      <td>-0.786664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.721834</td>\n",
       "      <td>-965.806274</td>\n",
       "      <td>-976.368469</td>\n",
       "      <td>0.024165</td>\n",
       "      <td>-0.426301</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.218821</td>\n",
       "      <td>-0.683896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902717</td>\n",
       "      <td>-1222.644531</td>\n",
       "      <td>-1147.203491</td>\n",
       "      <td>0.021102</td>\n",
       "      <td>-0.283253</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>-1.273913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.278217</td>\n",
       "      <td>-1066.943604</td>\n",
       "      <td>-898.298279</td>\n",
       "      <td>0.495132</td>\n",
       "      <td>0.262448</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.049222</td>\n",
       "      <td>-1.119319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.168541</td>\n",
       "      <td>-891.351013</td>\n",
       "      <td>-1131.902588</td>\n",
       "      <td>-0.370024</td>\n",
       "      <td>-0.702026</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>0.142519</td>\n",
       "      <td>-1.131805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.274324</td>\n",
       "      <td>-1053.560791</td>\n",
       "      <td>-1276.057861</td>\n",
       "      <td>0.089775</td>\n",
       "      <td>0.152454</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.192400</td>\n",
       "      <td>-0.278187</td>\n",
       "      <td>-1.188758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910571</td>\n",
       "      <td>-602.688110</td>\n",
       "      <td>-511.017853</td>\n",
       "      <td>0.054901</td>\n",
       "      <td>0.127118</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>-0.023890</td>\n",
       "      <td>-1.297848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.273959</td>\n",
       "      <td>-1229.041016</td>\n",
       "      <td>-1342.019409</td>\n",
       "      <td>0.090542</td>\n",
       "      <td>-0.132665</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.565484</td>\n",
       "      <td>-1.072818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.638302</td>\n",
       "      <td>-1041.720825</td>\n",
       "      <td>-1106.134766</td>\n",
       "      <td>-0.018970</td>\n",
       "      <td>-0.038510</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>-1.486796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.561697</td>\n",
       "      <td>-899.318115</td>\n",
       "      <td>-1137.301758</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>-0.530259</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.090512</td>\n",
       "      <td>-1.055230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.145741</td>\n",
       "      <td>-699.829224</td>\n",
       "      <td>-851.251282</td>\n",
       "      <td>0.030897</td>\n",
       "      <td>-0.140909</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.195441</td>\n",
       "      <td>-1.065948</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.261389</td>\n",
       "      <td>-990.644775</td>\n",
       "      <td>-1093.028931</td>\n",
       "      <td>0.411496</td>\n",
       "      <td>0.288018</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.224677</td>\n",
       "      <td>-1.061551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.286228</td>\n",
       "      <td>-1065.961304</td>\n",
       "      <td>-1275.822998</td>\n",
       "      <td>0.528431</td>\n",
       "      <td>0.333753</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.096443</td>\n",
       "      <td>-1.167575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.264018</td>\n",
       "      <td>-1169.833862</td>\n",
       "      <td>-1177.627075</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>-0.529103</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.100693</td>\n",
       "      <td>-1.346366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.447059</td>\n",
       "      <td>-1341.656006</td>\n",
       "      <td>-1495.912964</td>\n",
       "      <td>0.130402</td>\n",
       "      <td>-0.015537</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.074119</td>\n",
       "      <td>-1.150849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.224968</td>\n",
       "      <td>-962.831421</td>\n",
       "      <td>-978.403748</td>\n",
       "      <td>-0.224593</td>\n",
       "      <td>-0.386845</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.146041</td>\n",
       "      <td>-1.067107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.213148</td>\n",
       "      <td>-1201.903320</td>\n",
       "      <td>-1371.778320</td>\n",
       "      <td>-0.197974</td>\n",
       "      <td>-0.049176</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>0.161970</td>\n",
       "      <td>-1.178537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.340507</td>\n",
       "      <td>-1277.865234</td>\n",
       "      <td>-1312.694214</td>\n",
       "      <td>-0.192063</td>\n",
       "      <td>-0.259495</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>-0.093496</td>\n",
       "      <td>-1.303779</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.210283</td>\n",
       "      <td>-1192.726318</td>\n",
       "      <td>-1367.996094</td>\n",
       "      <td>0.199970</td>\n",
       "      <td>-0.273351</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>-1.302851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.584655</td>\n",
       "      <td>-1182.311279</td>\n",
       "      <td>-1085.873413</td>\n",
       "      <td>0.170448</td>\n",
       "      <td>0.272834</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>0.422914</td>\n",
       "      <td>-1.307062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.729976</td>\n",
       "      <td>-897.765137</td>\n",
       "      <td>-1103.164062</td>\n",
       "      <td>0.156889</td>\n",
       "      <td>-0.326801</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.255991</td>\n",
       "      <td>-1.227472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.483463</td>\n",
       "      <td>-1361.838867</td>\n",
       "      <td>-1576.533325</td>\n",
       "      <td>-0.427173</td>\n",
       "      <td>-0.475684</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.239715</td>\n",
       "      <td>-1.265921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.505636</td>\n",
       "      <td>-906.918701</td>\n",
       "      <td>-1264.314331</td>\n",
       "      <td>-0.099197</td>\n",
       "      <td>-0.539096</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.322100</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>-1.114159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.119132</td>\n",
       "      <td>-1011.007446</td>\n",
       "      <td>-829.601135</td>\n",
       "      <td>-0.385558</td>\n",
       "      <td>-0.697506</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.282569</td>\n",
       "      <td>-1.314151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.596720</td>\n",
       "      <td>-1021.607178</td>\n",
       "      <td>-940.555481</td>\n",
       "      <td>0.098938</td>\n",
       "      <td>-0.022898</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.120638</td>\n",
       "      <td>-1.578270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.698908</td>\n",
       "      <td>-836.899902</td>\n",
       "      <td>-851.956421</td>\n",
       "      <td>-0.312153</td>\n",
       "      <td>-0.425501</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>-1.834450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.901700</td>\n",
       "      <td>-1122.649902</td>\n",
       "      <td>-1016.844971</td>\n",
       "      <td>-0.421062</td>\n",
       "      <td>-0.465570</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>-0.011998</td>\n",
       "      <td>-1.446045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.434047</td>\n",
       "      <td>-1622.884155</td>\n",
       "      <td>-1788.308350</td>\n",
       "      <td>0.186304</td>\n",
       "      <td>-0.317662</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.143328</td>\n",
       "      <td>-1.386086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.529414</td>\n",
       "      <td>-1256.440674</td>\n",
       "      <td>-1493.575195</td>\n",
       "      <td>-0.239937</td>\n",
       "      <td>-0.520893</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.211600</td>\n",
       "      <td>0.030150</td>\n",
       "      <td>-1.635541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.665691</td>\n",
       "      <td>-1202.992188</td>\n",
       "      <td>-1388.834229</td>\n",
       "      <td>-0.081512</td>\n",
       "      <td>0.280342</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.254400</td>\n",
       "      <td>0.277489</td>\n",
       "      <td>-1.405381</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.682869</td>\n",
       "      <td>-1062.356934</td>\n",
       "      <td>-1207.409546</td>\n",
       "      <td>-0.209221</td>\n",
       "      <td>-0.766443</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.164314</td>\n",
       "      <td>-1.014838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.179151</td>\n",
       "      <td>-903.056641</td>\n",
       "      <td>-1156.935303</td>\n",
       "      <td>-0.029852</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.346400</td>\n",
       "      <td>0.133139</td>\n",
       "      <td>-0.956498</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.089637</td>\n",
       "      <td>-1104.021851</td>\n",
       "      <td>-1115.793091</td>\n",
       "      <td>0.121604</td>\n",
       "      <td>-0.139941</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.324264</td>\n",
       "      <td>-1.562245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.886509</td>\n",
       "      <td>-1084.672119</td>\n",
       "      <td>-1258.108521</td>\n",
       "      <td>-0.384199</td>\n",
       "      <td>-0.856298</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>-0.033484</td>\n",
       "      <td>-1.639428</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.605944</td>\n",
       "      <td>-1179.283325</td>\n",
       "      <td>-1174.216309</td>\n",
       "      <td>-0.179990</td>\n",
       "      <td>-0.376381</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.194300</td>\n",
       "      <td>0.096461</td>\n",
       "      <td>-1.842721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.939182</td>\n",
       "      <td>-858.744995</td>\n",
       "      <td>-1289.281494</td>\n",
       "      <td>0.242967</td>\n",
       "      <td>0.246414</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.291900</td>\n",
       "      <td>0.064635</td>\n",
       "      <td>-1.288738</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.353374</td>\n",
       "      <td>-1053.707520</td>\n",
       "      <td>-1152.392334</td>\n",
       "      <td>-0.224361</td>\n",
       "      <td>-0.469563</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>-0.035094</td>\n",
       "      <td>-2.275284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.240190</td>\n",
       "      <td>-1273.103760</td>\n",
       "      <td>-1234.897705</td>\n",
       "      <td>-0.299346</td>\n",
       "      <td>-0.317028</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>0.374221</td>\n",
       "      <td>-1.067831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442052</td>\n",
       "      <td>-814.433105</td>\n",
       "      <td>-1034.722290</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>-0.167015</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>-1.497773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500639</td>\n",
       "      <td>-1256.001221</td>\n",
       "      <td>-1421.037598</td>\n",
       "      <td>0.179576</td>\n",
       "      <td>0.099373</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.276976</td>\n",
       "      <td>-1.438161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.715137</td>\n",
       "      <td>-1121.509644</td>\n",
       "      <td>-1238.870239</td>\n",
       "      <td>0.318516</td>\n",
       "      <td>0.047401</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=108, training_loss=0.3900912070163974, metrics={'train_runtime': 1113.3209, 'train_samples_per_second': 0.784, 'train_steps_per_second': 0.097, 'total_flos': 0.0, 'train_loss': 0.3900912070163974, 'epoch': 2.9315068493150687})"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stoTFyleoO-I",
    "outputId": "7dfdb0af-779f-4c27-a6b0-d52510cd06a3"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/constitutional-ai-education/models/Llama-3.2-1B-dpo-edu/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/constitutional-ai-education/models/Llama-3.2-1B-dpo-edu/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/constitutional-ai-education/models/Llama-3.2-1B-dpo-edu/tokenizer.json')"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.save_pretrained(os.path.join(wrk_dir, \"models/Llama-3.2-1B-dpo-edu\"))\n",
    "tokenizer.save_pretrained(os.path.join(wrk_dir, \"models/Llama-3.2-1B-dpo-edu\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}